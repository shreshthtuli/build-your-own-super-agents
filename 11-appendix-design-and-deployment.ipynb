{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcfe63b",
   "metadata": {},
   "source": [
    "# 11. (Appendix) Designing & Deploying Scalable Agentic Systems\n",
    "\n",
    "## TL;DR (for practitioners)\n",
    "\n",
    "If you’re in a hurry, here’s the high-level recipe:\n",
    "\n",
    "1. **Define the agentic workflow** as roles (planner, tools executor, critic, router) and tools (APIs, databases, search, etc.).\n",
    "2. **Use Amazon Bedrock** for:\n",
    "\n",
    "   * Foundation models and **Agents for Bedrock** (single or multi-agent orchestrations). ([AWS Documentation][1])\n",
    "   * Knowledge bases, guardrails, and (increasingly) **AgentCore** for runtime, memory, and observability.\n",
    "3. **Use SageMaker** for classic MLOps:\n",
    "\n",
    "   * Train/domain-adapt your models, embedding models, ranking models, safety filters.\n",
    "   * Register them in **SageMaker Model Registry**, promote via CI/CD. ([AWS Documentation][2])\n",
    "4. **Orchestrate the system** via:\n",
    "\n",
    "   * **Agents for Bedrock / AgentCore** (built-in agent orchestration), plus\n",
    "   * **AWS Step Functions** and **Lambda / ECS / EKS** for workflows around the agents. ([AWS Documentation][3])\n",
    "5. **Persist memory and knowledge** using S3, DynamoDB, OpenSearch, and Bedrock Knowledge Bases.\n",
    "6. **Instrument heavily** with **CloudWatch metrics, logs, and traces**, plus AgentCore / CloudWatch Application Signals for agent-level observability. ([Amazon Web Services, Inc.][4])\n",
    "7. **Scale safely** using:\n",
    "\n",
    "   * Horizontal scaling of stateless components,\n",
    "   * Caching and model-routing (small vs large models),\n",
    "   * Guardrails, policy enforcement, and staged rollouts (canaries / blue–green).\n",
    "\n",
    "The rest of this markdown walks through all of this in depth, but still at a **no-code / architecture & MLOps** level.\n",
    "\n",
    "\n",
    "## What Is an “Agentic System” (in Cloud Terms)?\n",
    "\n",
    "In production, an **agentic system** is not just “an LLM with tools”. It’s a distributed application where:\n",
    "\n",
    "* **Agents** = LLM-driven components with a *role* (e.g., planner, data retriever, reasoner, code executor, critic).\n",
    "* **Tools** = APIs and services the agent can call (databases, SaaS APIs, internal microservices).\n",
    "* **Memory** = Long-term and short-term context (user profile, task history, RAG documents, intermediate steps).\n",
    "* **Orchestration** = Control flow across agents and tools: planning, retries, timeouts, routing, escalation.\n",
    "* **Guardrails & Governance** = Policies for safety, cost, compliance, and auditability.\n",
    "\n",
    "On AWS, this maps roughly to:\n",
    "\n",
    "* **Amazon Bedrock** for foundation models, agents, knowledge bases, guardrails. ([Amazon Web Services, Inc.][5])\n",
    "* **Agentic runtime & orchestration** via:\n",
    "\n",
    "  * **Agents for Bedrock** and **Bedrock AgentCore** for agent workflows, tooling, memory, and observability. ([Amazon Web Services, Inc.][6])\n",
    "  * **AWS Step Functions** and/or open-source frameworks (LangGraph, CrewAI, pydantic-ai, etc.) for higher-level workflows. ([AWS Documentation][3])\n",
    "* **SageMaker** for training, evaluation, and lifecycle of supporting models (embeddings, rerankers, safety classifiers, etc.).\n",
    "* **Cloud-native infra** for tools: Lambda, ECS/EKS, SQS, EventBridge, DynamoDB, S3, OpenSearch.\n",
    "\n",
    "\n",
    "## Non-Functional Requirements for Agentic Systems\n",
    "\n",
    "Before picking services, lock down your **NFRs**:\n",
    "\n",
    "* **Latency:** Chat-like apps want sub-2s “first token” latency; back-office agents can tolerate more.\n",
    "* **Throughput & concurrency:** How many parallel sessions? Spikes? Global vs regional traffic?\n",
    "* **Reliability & fault-tolerance:** What if a tool is down? A model throttles? A region fails?\n",
    "* **Cost constraints:** Per-session / per-user budget, cost allocation per team/product.\n",
    "* **Safety & compliance:** PII, PCI, HIPAA/GDPR, data residency.\n",
    "* **Governance:** Who can change prompts, tools, models? How are changes reviewed and rolled out?\n",
    "* **Auditability:** Can you reconstruct what an agent did and why?\n",
    "\n",
    "Everything else follows from this.\n",
    "\n",
    "\n",
    "## A Reference Architecture for Agentic AI on AWS\n",
    "\n",
    "Think in layers:\n",
    "\n",
    "### Experience & API Layer\n",
    "\n",
    "* **Channels**: Web/mobile app, internal console, Slack/Teams bot.\n",
    "* **Ingress**:\n",
    "\n",
    "  * **Amazon API Gateway / Amazon CloudFront** for public-facing APIs.\n",
    "  * Auth via Cognito / SSO / IAM roles.\n",
    "\n",
    "### Orchestration & Agents Layer\n",
    "\n",
    "* **Amazon Bedrock Agents / AgentCore** for:\n",
    "\n",
    "  * Defining agents with tools, knowledge bases, and guardrails.\n",
    "  * Multi-agent collaboration (planner agent + domain experts). ([AWS Documentation][3])\n",
    "* **AWS Step Functions** to:\n",
    "\n",
    "  * Wrap the agent calls in durable workflows (start → plan → act → verify → respond).\n",
    "  * Coordinate multiple services (logging, billing, notifications). ([Amazon Web Services, Inc.][7])\n",
    "* Optional:\n",
    "\n",
    "  * **Open-source frameworks** (LangGraph, CrewAI, pydantic-ai) hosted on ECS/EKS or Lambda, integrated with Bedrock models and AgentCore.\n",
    "\n",
    "### Tools & Microservices Layer\n",
    "\n",
    "* **Business tools**:\n",
    "\n",
    "  * REST/GraphQL APIs on **Lambda, ECS, or EKS**.\n",
    "  * Database-backed services on **RDS**, **DynamoDB**, etc.\n",
    "* **Observability tools**:\n",
    "\n",
    "  * CloudWatch Logs and Metrics.\n",
    "  * Incident management systems, ticketing APIs (Jira, ServiceNow).\n",
    "\n",
    "All tools must be:\n",
    "\n",
    "* **Stateless**, with externalized state in DBs or queues,\n",
    "* **Idempotent** or safely retryable,\n",
    "* **Strongly authenticated/authorized** (IAM, VPC, private link).\n",
    "\n",
    "### Memory, Knowledge, and State\n",
    "\n",
    "* **Long-term memory & knowledge**:\n",
    "\n",
    "  * **Amazon S3** as the data lake.\n",
    "  * **Bedrock Knowledge Bases** for RAG over documents.\n",
    "  * **OpenSearch** or vector DB (self-managed or via partner) for low-latency semantic search.\n",
    "* **Short-term / session memory**:\n",
    "\n",
    "  * **Amazon DynamoDB** or **ElastiCache (Redis)** for session state, conversation history pointers.\n",
    "  * **AgentCore Memory** for managed agent memory without custom infra. ([Amazon Web Services, Inc.][6])\n",
    "\n",
    "### Model & Data Science Layer (MLOps)\n",
    "\n",
    "* **SageMaker**:\n",
    "\n",
    "  * Data processing pipelines,\n",
    "  * Model training (embeddings, ranking, safety filters),\n",
    "  * Evaluation jobs,\n",
    "  * **Model Registry** for versioning & approvals. ([AWS Documentation][2])\n",
    "* **Integration with Bedrock**:\n",
    "\n",
    "  * Use Bedrock models for core LLM tasks; SageMaker models as tools (e.g., classifier endpoints).\n",
    "\n",
    "\n",
    "## Designing the Agentic Workflow\n",
    "\n",
    "### Decompose the Use Case into Agent Roles\n",
    "\n",
    "For any use case (e.g., “cloud ops copilot”, “biopharma business expert”), identify roles:\n",
    "\n",
    "* **Router / Intent classifier**: Which agent or workflow should handle this?\n",
    "* **Planner**: Breaks the task into steps and selects tools/agents.\n",
    "* **Domain agents**: Specialized in support, billing, infra, legal, etc.\n",
    "* **Critic / verifier**: Checks outputs (hallucinations, safety, consistency).\n",
    "* **Summarizer / presenter**: Formats responses for end-users or APIs.\n",
    "\n",
    "In Bedrock, each of these can be an **agent definition**, or you can use **multi-agent collaboration** within a single Bedrock Agents setup. ([Amazon Web Services, Inc.][8])\n",
    "\n",
    "### Tool Design Principles\n",
    "\n",
    "Tools define how agents act on the world. Design them as:\n",
    "\n",
    "* **Clear, narrow APIs**: e.g., `get_ticket_status`, `scale_service`, `list_failed_deployments`.\n",
    "* **Typed and validated** inputs/outputs, documented in OpenAPI where possible.\n",
    "* **Secure by default**:\n",
    "\n",
    "  * Use **AgentCore Identity** or scoped IAM roles for tools that access AWS or third-party services. ([Amazon Web Services, Inc.][6])\n",
    "  * Enforce *least privilege* and explicit allow-lists.\n",
    "* **Observable**: Log each call with correlation IDs and agent metadata.\n",
    "\n",
    "### Memory & Knowledge Strategy\n",
    "\n",
    "Avoid a single “magic memory” bucket.\n",
    "\n",
    "* **Episodic memory**: Per-conversation or per-session context, stored in DynamoDB/Redis, with TTLs.\n",
    "* **Semantic memory (RAG)**:\n",
    "\n",
    "  * Knowledge Bases in Bedrock backed by S3/OpenSearch.\n",
    "  * Clear separation between public knowledge, team knowledge, and per-tenant private knowledge.\n",
    "* **Working memory**:\n",
    "\n",
    "  * Intermediate steps, tool results, scratchpads; often ephemeral but logged for debugging.\n",
    "\n",
    "### Safety, Guardrails & Policy Enforcement\n",
    "\n",
    "Use **multiple layers**:\n",
    "\n",
    "* **Bedrock Guardrails**:\n",
    "\n",
    "  * Content filters, topic restrictions, safety settings. ([Amazon Web Services, Inc.][5])\n",
    "* **Custom safety models**:\n",
    "\n",
    "  * Trained on SageMaker (toxicity detectors, PII detectors, policy compliance).\n",
    "* **Policy-aware tools**:\n",
    "\n",
    "  * Tools themselves should validate that requested action is allowed for given user/role.\n",
    "* **Audit logging**:\n",
    "\n",
    "  * Every action and tool call traceable to user, agent, and policy decision.\n",
    "\n",
    "\n",
    "## MLOps Lifecycle for Agentic AI\n",
    "\n",
    "Agentic systems are **multi-model, multi-prompt, multi-tool**. Your MLOps must manage **all three**: models, prompts, and tools.\n",
    "\n",
    "### Data & Feature Pipelines\n",
    "\n",
    "* **Raw data** in S3 (logs, chat transcripts, tool responses, business metrics).\n",
    "* **Feature stores & embeddings**:\n",
    "\n",
    "  * Embedding pipelines in SageMaker for documents and user profiles.\n",
    "  * Periodic jobs to refresh indexes in knowledge bases or vector stores.\n",
    "* **Labelling & feedback loops**:\n",
    "\n",
    "  * Human feedback on agent interactions (was this helpful/safe?).\n",
    "  * Weak labels from monitoring (tool mismatch, errors, escalations).\n",
    "\n",
    "### Model Training & Evaluation (SageMaker)\n",
    "\n",
    "Typical supporting models:\n",
    "\n",
    "* Embedding models for RAG.\n",
    "* Rerankers or recommendation models.\n",
    "* Safety filters (toxicity, PII).\n",
    "* Routing models (which agent/tool/model to use).\n",
    "\n",
    "Use **SageMaker Pipelines** to:\n",
    "\n",
    "* Automate data preparation → training → evaluation → registration.\n",
    "* Store trained models and metrics in **Model Registry**, with stage tags like *staging* and *production*. ([AWS Documentation][2])\n",
    "\n",
    "### Prompt & Agent Versioning\n",
    "\n",
    "Treat prompts and agent configs like code:\n",
    "\n",
    "* Version-control prompts, tool schemas, and agent graphs in Git.\n",
    "* Use environment-specific configs (dev / staging / prod).\n",
    "* Run automated tests:\n",
    "\n",
    "  * Regression tests on curated prompt suites.\n",
    "  * “Safety tests” against red-team datasets.\n",
    "\n",
    "### CI/CD for Agentic Systems\n",
    "\n",
    "Typical flow:\n",
    "\n",
    "1. Developer changes prompts/agents/tools in Git.\n",
    "2. CI:\n",
    "\n",
    "   * Lints prompts/configs.\n",
    "   * Runs synthetic tests using Bedrock in a dev environment.\n",
    "3. CD:\n",
    "\n",
    "   * Deploys updated Bedrock agents or AgentCore configurations to staging.\n",
    "   * Runs shadow traffic or A/B tests.\n",
    "   * On approval, promotes to production.\n",
    "\n",
    "AWS tools: CodeCommit/CodeBuild/CodePipeline or GitHub Actions + AWS CDK/CloudFormation.\n",
    "\n",
    "\n",
    "## Example End-to-End System: Cloud Operations Copilot\n",
    "\n",
    "Let’s ground this in a concrete (but code-free) example, inspired by AWS scenarios where agents triage **CloudWatch Logs** and mitigate incidents. ([Amazon Web Services, Inc.][9])\n",
    "\n",
    "### Roles & Agents\n",
    "\n",
    "* **Triage Agent**:\n",
    "\n",
    "  * Reads error summaries from CloudWatch Logs Insights.\n",
    "  * Classifies severity and suggests likely root cause.\n",
    "* **Remediation Agent**:\n",
    "\n",
    "  * Proposes runbooks or direct actions (restart service, roll back deployment).\n",
    "  * Interfaces with Systems Manager Automation / Change Manager.\n",
    "* **Communicator Agent**:\n",
    "\n",
    "  * Drafts human-readable updates for Slack/Teams, incident tickets.\n",
    "\n",
    "These can be **multi-agent collaborators inside Bedrock** (using Bedrock Agents multi-agent features), or orchestrated externally via Step Functions and AgentCore. ([Amazon Web Services, Inc.][8])\n",
    "\n",
    "### Tools\n",
    "\n",
    "* **Log analysis tool**:\n",
    "\n",
    "  * Calls CloudWatch Logs Insights to query error patterns.\n",
    "* **Deployment tool**:\n",
    "\n",
    "  * Calls CodeDeploy / ECS APIs to roll back tasks.\n",
    "* **Runbook tool**:\n",
    "\n",
    "  * Looks up remediation steps stored in S3 or a knowledge base.\n",
    "* **Notification tool**:\n",
    "\n",
    "  * Sends updates via SNS/Slack webhook.\n",
    "\n",
    "### Orchestration\n",
    "\n",
    "* **Step Functions** orchestrates:\n",
    "\n",
    "  1. Trigger from CloudWatch alarm or an operator.\n",
    "  2. Invoke Triage Agent (Bedrock).\n",
    "  3. Parallel branch:\n",
    "\n",
    "     * Run more detailed diagnostics.\n",
    "     * Notify on-call engineer.\n",
    "  4. If low/medium severity, let Remediation Agent propose and possibly execute an automated runbook.\n",
    "  5. Use Communicator Agent to update incident tickets and channels.\n",
    "\n",
    "* All of this is instrumented with **CloudWatch metrics** and **traces**, with **AgentCore Observability** and CloudWatch Application Signals capturing agent steps and tool calls. ([Amazon Web Services, Inc.][10])\n",
    "\n",
    "\n",
    "## Scaling Strategies for Agentic Workloads\n",
    "\n",
    "### Concurrency, Throttling & Backpressure\n",
    "\n",
    "* Understand **Bedrock limits** for model calls and configure:\n",
    "\n",
    "  * Rate limits in API Gateway.\n",
    "  * Concurrency limits in Lambda or ECS services.\n",
    "* Use **queues** (SQS, EventBridge) for non-interactive work to smooth spikes.\n",
    "* For interactive chat:\n",
    "\n",
    "  * Use streaming responses from Bedrock to deliver tokens early while longer tools run in the background.\n",
    "\n",
    "### Caching\n",
    "\n",
    "* **Prompt-level caching**:\n",
    "\n",
    "  * Cache “expensive” results (e.g., summarizing a static document) in DynamoDB or Redis.\n",
    "* **Embedding caching**:\n",
    "\n",
    "  * Avoid re-computing embeddings for unchanged documents or frequent queries.\n",
    "* **Tool result caching**:\n",
    "\n",
    "  * Cache stable API responses (configuration, catalogs).\n",
    "\n",
    "### Model & Agent Routing for Cost/Latency\n",
    "\n",
    "* **Tiered models** in Bedrock (small, medium, large; different vendors). ([Amazon Web Services, Inc.][5])\n",
    "* Strategies:\n",
    "\n",
    "  * Use a **smaller / cheaper model** for lightweight tasks, and escalate to larger models only when needed.\n",
    "  * Use a **router model** or heuristic to choose which model or agent is appropriate.\n",
    "* For multi-agent setups:\n",
    "\n",
    "  * Avoid “agent explosion”: have a router that limits which agents get invoked per request.\n",
    "\n",
    "### Horizontal Scaling of Tools and Orchestrators\n",
    "\n",
    "* Design **stateless** orchestrator components:\n",
    "\n",
    "  * Lambdas can scale quickly for spiky workloads.\n",
    "  * ECS/EKS services for more predictable high-volume flows.\n",
    "* Use **auto scaling policies** based on:\n",
    "\n",
    "  * Queue depth,\n",
    "  * Error rates,\n",
    "  * Latency percentiles (p95, p99).\n",
    "\n",
    "### Multi-Region and Multi-Account\n",
    "\n",
    "* For global users:\n",
    "\n",
    "  * Deploy agents in multiple regions close to users.\n",
    "  * Use **Route 53** or CloudFront for routing.\n",
    "* For large organizations:\n",
    "\n",
    "  * Multi-account structure with central governance:\n",
    "\n",
    "    * Central **Bedrock / CloudWatch observability** account,\n",
    "    * Application accounts hosting tools and workloads. ([Medium][11])\n",
    "\n",
    "\n",
    "## Observability, Monitoring, and Evaluation\n",
    "\n",
    "Agentic systems are *complex*. You need **deep observability**:\n",
    "\n",
    "### Telemetry Pillars\n",
    "\n",
    "* **Metrics**:\n",
    "\n",
    "  * Latency per step (LLM calls, tools).\n",
    "  * Success/failure rates, retries.\n",
    "  * Cost metrics (tokens, Bedrock usage).\n",
    "* **Logs**:\n",
    "\n",
    "  * Structured logs with correlation IDs.\n",
    "  * Redacted inputs/outputs where necessary.\n",
    "* **Traces**:\n",
    "\n",
    "  * End-to-end traces from user request → agents → tools → response.\n",
    "\n",
    "**AWS CloudWatch** and **AgentCore Observability** now provide features specifically for generative AI and agents (Application Signals, Bedrock observability, multi-framework support). ([Amazon Web Services, Inc.][4])\n",
    "\n",
    "### Agentic-Specific Metrics\n",
    "\n",
    "Track:\n",
    "\n",
    "* **Tool utilization**:\n",
    "\n",
    "  * Frequency and latency of each tool.\n",
    "  * Error codes and failure rates.\n",
    "* **Agent behavior**:\n",
    "\n",
    "  * Number of steps per request.\n",
    "  * Looping/oscillation detection (too many iterations).\n",
    "  * Escalation rate (how often agents ask humans for help).\n",
    "* **Quality & safety**:\n",
    "\n",
    "  * User satisfaction scores (thumbs up/down).\n",
    "  * Safety incidents (flagged content, blocked tool calls).\n",
    "  * Consistency between tool outputs and final responses.\n",
    "\n",
    "### Continuous Evaluation\n",
    "\n",
    "* Maintain **golden test sets**:\n",
    "\n",
    "  * Realistic scenarios with expected outputs or constraints.\n",
    "* Periodically run:\n",
    "\n",
    "  * Offline evaluations (accuracy, helpfulness, safety).\n",
    "  * **Load tests** to ensure capacity and SLO adherence.\n",
    "* Integrate evaluation with CI:\n",
    "\n",
    "  * Block deployments if regressions in quality or safety exceed thresholds.\n",
    "\n",
    "\n",
    "## Governance, Risk, and Compliance\n",
    "\n",
    "### Permissions & Identity\n",
    "\n",
    "* Use **IAM roles** with least privilege for:\n",
    "\n",
    "  * Agents (via AgentCore Identity),\n",
    "  * Tools,\n",
    "  * Orchestrators (Lambdas / ECS tasks). ([Amazon Web Services, Inc.][6])\n",
    "* Separate roles for:\n",
    "\n",
    "  * Model access,\n",
    "  * Data access,\n",
    "  * Write vs read operations.\n",
    "\n",
    "### Data Governance\n",
    "\n",
    "* Encrypt data at rest (KMS) and in transit (TLS).\n",
    "* Tag and isolate sensitive datasets; ensure correct residency.\n",
    "* Implement **data retention policies**:\n",
    "\n",
    "  * How long do you store prompts, tool calls, and transcripts?\n",
    "  * Can users request deletion?\n",
    "\n",
    "### Change Management & Rollback\n",
    "\n",
    "* Treat **agents as deployable artifacts**:\n",
    "\n",
    "  * Use staging and production environments.\n",
    "  * Implement **canary deployments** (route a small percentage of traffic to new versions).\n",
    "  * Have a **one-click rollback** path.\n",
    "\n",
    "### Responsible AI\n",
    "\n",
    "* Maintain **model cards** and **agent cards** describing:\n",
    "\n",
    "  * Intended use,\n",
    "  * Limitations,\n",
    "  * Safety mitigations.\n",
    "* Periodically review:\n",
    "\n",
    "  * Bias assessments (especially if agents make high-stakes decisions).\n",
    "  * Misuse patterns and new threat models.\n",
    "\n",
    "\n",
    "## Implementation Checklist\n",
    "\n",
    "Here’s a pragmatic sequence for building a real-world agentic system on AWS:\n",
    "\n",
    "1. **Scope & design**\n",
    "\n",
    "   * Define user journeys, agent roles, tools, success metrics.\n",
    "2. **Choose AWS components**\n",
    "\n",
    "   * Bedrock models + Agents/AgentCore for core agent logic.\n",
    "   * SageMaker for supporting models and MLOps.\n",
    "   * Step Functions + Lambda/ECS for orchestration & tools.\n",
    "3. **Prototype**\n",
    "\n",
    "   * Single-region, limited-traffic POC.\n",
    "   * Simple logging, manual evaluation.\n",
    "4. **Hardening**\n",
    "\n",
    "   * Add guardrails and safety filters.\n",
    "   * Introduce proper observability and tracing.\n",
    "   * Build CI/CD and basic canary deployment.\n",
    "5. **Scale-out**\n",
    "\n",
    "   * Optimize for latency and cost (routing, caching).\n",
    "   * Add multi-agent collaboration where beneficial.\n",
    "   * Implement auto scaling.\n",
    "6. **Continuous improvement**\n",
    "\n",
    "   * Close the feedback loop from telemetry & user feedback to training data.\n",
    "   * Regularly refresh knowledge bases and retrain supporting models.\n",
    "\n",
    "\n",
    "## Common Pitfalls & Anti-Patterns\n",
    "\n",
    "* **“Single giant agent”**: One agent doing everything with a massive prompt. Hard to debug, scale, and govern.\n",
    "* **No explicit tool contracts**: Letting the LLM “invent” tool usage instead of having strict schemas.\n",
    "* **Unbounded loops**: Agents that keep thinking & calling tools indefinitely—always add step and time limits.\n",
    "* **Hidden state**: Storing critical context only in prompts, not in explicit memory/state stores.\n",
    "* **No observability**: Debugging via ad hoc logs instead of structured metrics, logs, and traces.\n",
    "* **Prompt sprawl**: Unversioned prompts directly edited in consoles; use Git and environments instead.\n",
    "\n",
    "\n",
    "## Where SageMaker, Bedrock, and AgentCore Each Fit\n",
    "\n",
    "To summarize their roles in an **agentic MLOps** stack:\n",
    "\n",
    "* **Amazon Bedrock**\n",
    "\n",
    "  * Foundation models (Claude, etc.).\n",
    "  * Knowledge bases and guardrails.\n",
    "  * **Agents for Bedrock** for integrated tool use and multi-agent workflows. ([AWS Documentation][1])\n",
    "\n",
    "* **Amazon Bedrock AgentCore** (emerging platform)\n",
    "\n",
    "  * Purpose-built runtime for agents.\n",
    "  * Managed memory, identity, gateway, code interpreter, browser tool.\n",
    "  * Deep observability for agent steps and interactions. ([Amazon Web Services, Inc.][6])\n",
    "\n",
    "* **Amazon SageMaker**\n",
    "\n",
    "  * Classic MLOps backbone:\n",
    "\n",
    "    * Training pipelines,\n",
    "    * Model Registry and approvals,\n",
    "    * Batch/online endpoints for supporting models.\n",
    "  * Ideal for domain-specific ML around your agents.\n",
    "\n",
    "Together, they allow you to build **production-grade, scalable, observable, and governable agentic systems** that go far beyond “just calling an LLM”.\n",
    "\n",
    "[1]: https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html?utm_source=chatgpt.com \"Automate tasks in your application using AI agents\"\n",
    "[2]: https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html?utm_source=chatgpt.com \"Model Registration Deployment with Model Registry\"\n",
    "[3]: https://docs.aws.amazon.com/prescriptive-guidance/latest/agentic-ai-patterns/multi-agent-collaboration.html?utm_source=chatgpt.com \"Multi-agent collaboration - AWS Prescriptive Guidance\"\n",
    "[4]: https://aws.amazon.com/blogs/mt/observing-agentic-ai-workloads-using-amazon-cloudwatch/?utm_source=chatgpt.com \"Observing Agentic AI workloads using ...\"\n",
    "[5]: https://aws.amazon.com/bedrock/?utm_source=chatgpt.com \"Amazon Bedrock - Generative AI\"\n",
    "[6]: https://aws.amazon.com/bedrock/agentcore/?utm_source=chatgpt.com \"Amazon Bedrock AgentCore\"\n",
    "[7]: https://aws.amazon.com/blogs/machine-learning/orchestrate-generative-ai-workflows-with-amazon-bedrock-and-aws-step-functions/?utm_source=chatgpt.com \"Orchestrate generative AI workflows with Amazon Bedrock ...\"\n",
    "[8]: https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-multi-agent-business-expert-using-amazon-bedrock/?utm_source=chatgpt.com \"Build an intelligent multi-agent business expert using ...\"\n",
    "[9]: https://aws.amazon.com/blogs/mt/enable-cloud-operations-workflows-with-generative-ai-using-agents-for-amazon-bedrock-and-amazon-cloudwatch-logs/?utm_source=chatgpt.com \"Enable cloud operations workflows with generative AI ...\"\n",
    "[10]: https://aws.amazon.com/blogs/machine-learning/build-trustworthy-ai-agents-with-amazon-bedrock-agentcore-observability/?utm_source=chatgpt.com \"Build trustworthy AI agents with Amazon Bedrock ...\"\n",
    "[11]: https://medium.com/aws-in-plain-english/cloudwatchs-new-era-centralized-monitoring-for-ai-agents-and-multi-account-workloads-3b6bcb2c4656?utm_source=chatgpt.com \"CloudWatch's New Era: Centralized Monitoring for AI ...\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
