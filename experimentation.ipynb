{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c3690b",
   "metadata": {},
   "source": [
    "\n",
    "# End-to-End Experimentation & Causal Inference Tutorial (with CATE)\n",
    "**From first principles → advanced methods.**  \n",
    "You’ll build cohorts, size an experiment (power), run A/B with CUPED, estimate causal effects with back-door OLS and IV (2SLS), handle exposure bias with IPW, and **estimate heterogeneous treatment effects (CATE)** using meta-learners with Random Forests (a practical stand‑in for causal forests).\n",
    "\n",
    "**What you’ll learn**  \n",
    "- Potential outcomes, counterfactuals, confounders, instruments, exposure bias  \n",
    "- Cohorting and experiment design basics  \n",
    "- Power analysis & variance reduction (CUPED)  \n",
    "- Causal estimation: back-door OLS and 2SLS IV  \n",
    "- **CATE estimation** with T‑learner / S‑learner / X‑learner (Random Forests)  \n",
    "- Uplift targeting and policy evaluation ideas\n",
    "\n",
    "> Note: True “Causal Forests” are implemented in packages like `econml` or `grf`. Here we implement **meta‑learner** approaches with `sklearn` Random Forests which deliver forest‑style **nonlinear CATE** approximations that work well in practice and are easy to run anywhere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926b43a",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setup & Synthetic Data\n",
    "We simulate a realistic product setting with:\n",
    "- **Confounding** (treatment is more likely among highly active users)\n",
    "- A **randomized encouragement** `Z` (valid instrument for 2SLS)\n",
    "- **Exposure** counts that correlate with outcomes (exposure bias)\n",
    "- A **true structural effect** `tau = 1.2` so we can judge estimators\n",
    "\n",
    "Run the next cell to generate the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS, add_constant, Logit\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---- simulate users ----\n",
    "N = 50_000\n",
    "signup_month = rng.integers(1, 7, size=N)\n",
    "segment = rng.choice([\"casual\", \"regular\", \"vip\"], size=N, p=[0.5, 0.4, 0.1])\n",
    "age = rng.normal(35, 10, size=N).clip(18, 75)\n",
    "activity_score = rng.gamma(shape=2.0, scale=2.0, size=N)\n",
    "u_latent = rng.normal(0, 1, size=N)\n",
    "\n",
    "# pre-experiment metric (for CUPED)\n",
    "pre_metric = 5 + 0.25 * activity_score + 0.02 * (age - 35) + 0.8 * u_latent + rng.normal(0, 1.0, N)\n",
    "\n",
    "# Instrument: randomized encouragement\n",
    "Z = rng.binomial(1, 0.5, size=N)\n",
    "\n",
    "# Non-random treatment: encouraged + latent inclination drive T\n",
    "logit_T = -0.2 + 1.1 * Z + 0.6 * u_latent + 0.15 * (activity_score > 2.5)\n",
    "p_T = 1 / (1 + np.exp(-logit_T))\n",
    "T = rng.binomial(1, p_T, size=N)\n",
    "\n",
    "# Exposure (dose)\n",
    "lambda_exposure = 0.8 + 1.3 * T + 0.25 * activity_score\n",
    "exposure = rng.poisson(lam=np.maximum(lambda_exposure, 0.1))\n",
    "\n",
    "# Structural outcome\n",
    "tau = 1.2           # true treatment effect\n",
    "beta_exp = 0.15     # effect of exposure (mediator-like)\n",
    "theta_u = 1.0       # unobserved component\n",
    "theta_cov = 0.02\n",
    "theta_seg = {\"casual\": 0.0, \"regular\": 0.4, \"vip\": 1.0}\n",
    "seg_eff = np.array([theta_seg[s] for s in segment])\n",
    "\n",
    "Y = (\n",
    "    2.0 + tau*T + beta_exp*exposure\n",
    "    + theta_cov*(age - 35)\n",
    "    + 0.3*activity_score\n",
    "    + seg_eff + theta_u*u_latent\n",
    "    + rng.normal(0, 1.0, N)\n",
    ")\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"signup_month\": signup_month,\n",
    "    \"segment\": segment,\n",
    "    \"age\": age,\n",
    "    \"activity_score\": activity_score,\n",
    "    \"pre_metric\": pre_metric,\n",
    "    \"Z\": Z,\n",
    "    \"T\": T,\n",
    "    \"exposure\": exposure,\n",
    "    \"Y\": Y\n",
    "})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7182e83c",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Cohorts for baseline sanity & stratification\n",
    "Cohorts let you check balance, set up stratified designs, and monitor drift across comparable slices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97982820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cohort_cols = [\"signup_month\", \"segment\"]\n",
    "cohort_summary = (\n",
    "    df.groupby(cohort_cols)\n",
    "      .agg(n=(\"Y\",\"size\"),\n",
    "           mean_Y=(\"Y\",\"mean\"),\n",
    "           mean_pre=(\"pre_metric\",\"mean\"),\n",
    "           treat_rate=(\"T\",\"mean\"))\n",
    "      .reset_index()\n",
    "      .sort_values(cohort_cols)\n",
    ")\n",
    "cohort_summary.head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca46c1b",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Power analysis (two-sample t-test approximation)\n",
    "Pick a minimum detectable effect (MDE) and estimate **n per arm**. Then draw a **power curve** for intuition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "effect_target = 0.6\n",
    "std_est = df[\"Y\"].std()\n",
    "cohen_d = effect_target / std_est\n",
    "\n",
    "n_per_group = int(np.ceil(TTestIndPower().solve_power(effect_size=cohen_d, alpha=0.05, power=0.8)))\n",
    "print(\"Needed per group (approx):\", n_per_group)\n",
    "\n",
    "# power vs true effect, at this fixed n\n",
    "effects = np.linspace(0.2, 1.2, 6)\n",
    "powers = [TTestIndPower().power(effect_size=e/std_est, nobs1=n_per_group, alpha=0.05) for e in effects]\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(effects, powers, marker=\"o\")\n",
    "plt.title(f\"Power vs Effect (n/group ≈ {n_per_group})\")\n",
    "plt.xlabel(\"True Effect on Y\")\n",
    "plt.ylabel(\"Power\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ede5f",
   "metadata": {},
   "source": [
    "\n",
    "## 4. A/B test and CUPED variance reduction\n",
    "We simulate a randomized **`ab_group`** on a 20% subsample, measure the naive diff‑in‑means, then apply **CUPED** using the correlated **pre_metric** to reduce variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c2b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.default_rng(7)\n",
    "mask_ab = rng.random(df.shape[0]) < 0.2\n",
    "df_ab = df.loc[mask_ab].copy()\n",
    "\n",
    "df_ab[\"ab_group\"] = rng.binomial(1, 0.5, size=df_ab.shape[0])\n",
    "delta_true = 0.8\n",
    "df_ab[\"Y_ab\"] = df_ab[\"Y\"] + delta_true*df_ab[\"ab_group\"] + rng.normal(0, 0.5, df_ab.shape[0])\n",
    "\n",
    "grp0 = df_ab.loc[df_ab.ab_group==0, \"Y_ab\"]\n",
    "grp1 = df_ab.loc[df_ab.ab_group==1, \"Y_ab\"]\n",
    "diff = grp1.mean() - grp0.mean()\n",
    "print(\"Naive diff:\", diff)\n",
    "\n",
    "# CUPED\n",
    "pre = df_ab[\"pre_metric\"]\n",
    "theta = np.cov(df_ab[\"Y_ab\"], pre, ddof=1)[0,1] / np.var(pre, ddof=1)\n",
    "Y_cuped = df_ab[\"Y_ab\"] - theta*(pre - pre.mean())\n",
    "\n",
    "grp0_c = Y_cuped[df_ab.ab_group==0]\n",
    "grp1_c = Y_cuped[df_ab.ab_group==1]\n",
    "diff_c = grp1_c.mean() - grp0_c.mean()\n",
    "print(\"CUPED diff:\", diff_c)\n",
    "\n",
    "# plots\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(grp0, bins=40, alpha=0.6, label=\"Control Y_ab\", density=True)\n",
    "plt.hist(grp1, bins=40, alpha=0.6, label=\"Variant Y_ab\", density=True)\n",
    "plt.title(\"A/B outcome distributions (naive)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(grp0_c, bins=40, alpha=0.6, label=\"Control (CUPED)\", density=True)\n",
    "plt.hist(grp1_c, bins=40, alpha=0.6, label=\"Variant (CUPED)\", density=True)\n",
    "plt.title(\"A/B outcome distributions (CUPED-adjusted)\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005bc5c0",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Causal estimation: back‑door OLS and 2SLS IV\n",
    "- **Back‑door OLS:** control for observed confounders \\(X\\) that block spurious paths.  \n",
    "- **IV / 2SLS:** use a randomized encouragement `Z` that shifts `T` but has no direct path to `Y` except via `T`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a618faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Naive OLS\n",
    "ols_naive = OLS(df[\"Y\"], add_constant(df[[\"T\"]])).fit()\n",
    "\n",
    "# Back-door OLS\n",
    "enc = OneHotEncoder(drop=\"first\", sparse=False, handle_unknown=\"ignore\")\n",
    "seg_oh = enc.fit_transform(df[[\"segment\"]])\n",
    "seg_cols = [f\"segment_{c}\" for c in enc.categories_[0][1:]]\n",
    "Xb = pd.DataFrame(seg_oh, columns=seg_cols)\n",
    "Xb[\"T\"] = df[\"T\"].values\n",
    "Xb[\"age\"] = df[\"age\"].values\n",
    "Xb[\"activity_score\"] = df[\"activity_score\"].values\n",
    "ols_backdoor = OLS(df[\"Y\"], add_constant(Xb)).fit()\n",
    "\n",
    "# 2SLS (manual)\n",
    "X1 = pd.DataFrame(seg_oh, columns=seg_cols)\n",
    "X1[\"Z\"] = df[\"Z\"].values\n",
    "X1[\"age\"] = df[\"age\"].values\n",
    "X1[\"activity_score\"] = df[\"activity_score\"].values\n",
    "stage1 = OLS(df[\"T\"], add_constant(X1)).fit()\n",
    "T_hat = stage1.fittedvalues\n",
    "\n",
    "X2 = pd.DataFrame(seg_oh, columns=seg_cols)\n",
    "X2[\"T_hat\"] = T_hat.values\n",
    "X2[\"age\"] = df[\"age\"].values\n",
    "X2[\"activity_score\"] = df[\"activity_score\"].values\n",
    "stage2 = OLS(df[\"Y\"], add_constant(X2)).fit()\n",
    "\n",
    "print(\"Naive OLS (Y~T):\", round(ols_naive.params[\"T\"],3))\n",
    "print(\"Back-door OLS:\", round(ols_backdoor.params[\"T\"],3))\n",
    "print(\"2SLS IV:\", round(stage2.params[\"T_hat\"],3))\n",
    "print(\"True tau:\", 1.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c13c4",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Exposure bias & IPW correction\n",
    "If high‑activity users both **get treated more** and **perform better**, naive estimates inflate the effect. Estimate the **propensity** \\(e(X)=P(T=1|X)\\) and compute an **IPW ATE**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaa7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xp = pd.DataFrame(seg_oh, columns=seg_cols)\n",
    "Xp[\"age\"] = df[\"age\"].values\n",
    "Xp[\"activity_score\"] = df[\"activity_score\"].values\n",
    "\n",
    "logit = Logit(df[\"T\"], add_constant(Xp)).fit(disp=False)\n",
    "ps = logit.predict(add_constant(Xp)).clip(1e-3, 1-1e-3)\n",
    "\n",
    "w = np.where(df[\"T\"]==1, 1/ps, 1/(1-ps))\n",
    "ds1 = DescrStatsW(df.loc[df.T==1,\"Y\"], w[df.T==1], ddof=1)\n",
    "ds0 = DescrStatsW(df.loc[df.T==0,\"Y\"], w[df.T==0], ddof=1)\n",
    "\n",
    "ate_naive = df.loc[df.T==1,\"Y\"].mean() - df.loc[df.T==0,\"Y\"].mean()\n",
    "ate_ipw = ds1.mean - ds0.mean\n",
    "print(\"Naive diff (T groups):\", round(ate_naive,3))\n",
    "print(\"IPW ATE:\", round(ate_ipw,3))\n",
    "print(\"True tau:\", 1.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264eec4b",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Heterogeneous Treatment Effects (CATE)\n",
    "We now estimate **CATE(x) = E[Y(1)−Y(0) | X=x]**.  \n",
    "We’ll implement three **meta‑learner** strategies using Random Forests (nonparametric, interaction‑rich):\n",
    "\n",
    "- **T‑learner (two models):** fit \\(\\mu_1(x)=E[Y|X=x,T=1]\\) and \\(\\mu_0(x)=E[Y|X=x,T=0]\\), then \\(\\widehat{\\tau}(x)=\\mu_1(x)-\\mu_0(x)\\).\n",
    "- **S‑learner (single model):** fit \\(m(x,t)=E[Y|X=x,T=t]\\) on features `[X, T]`, then predict \\(m(x,1)-m(x,0)\\).\n",
    "- **X‑learner:** (a refinement) first build T‑learner, compute pseudo-outcomes \\(D_1=Y-\\mu_0(X)\\) for treated and \\(D_0=\\mu_1(X)-Y\\) for control; then learn separate models mapping \\(X\\to D\\) and combine.\n",
    "\n",
    "These recover **nonlinear**, segment‑specific effects and approximate causal forests behavior without extra dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20732573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Features X\n",
    "X_base = pd.DataFrame(seg_oh, columns=seg_cols)\n",
    "X_base[\"age\"] = df[\"age\"].values\n",
    "X_base[\"activity_score\"] = df[\"activity_score\"].values\n",
    "X_base[\"pre_metric\"] = df[\"pre_metric\"].values\n",
    "X = X_base.values\n",
    "y = df[\"Y\"].values\n",
    "t = df[\"T\"].values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te, t_tr, t_te = train_test_split(X, y, t, test_size=0.3, random_state=123, stratify=t)\n",
    "\n",
    "# --- T-learner ---\n",
    "rf_t1 = RandomForestRegressor(n_estimators=200, random_state=0, n_jobs=-1)\n",
    "rf_t0 = RandomForestRegressor(n_estimators=200, random_state=1, n_jobs=-1)\n",
    "\n",
    "rf_t1.fit(X_tr[t_tr==1], y_tr[t_tr==1])\n",
    "rf_t0.fit(X_tr[t_tr==0], y_tr[t_tr==0])\n",
    "\n",
    "mu1 = rf_t1.predict(X_te)\n",
    "mu0 = rf_t0.predict(X_te)\n",
    "cate_T = mu1 - mu0\n",
    "\n",
    "# --- S-learner ---\n",
    "rf_s = RandomForestRegressor(n_estimators=300, random_state=2, n_jobs=-1)\n",
    "X_s_tr = np.c_[X_tr, t_tr]\n",
    "X_s_te_1 = np.c_[X_te, np.ones_like(t_te)]\n",
    "X_s_te_0 = np.c_[X_te, np.zeros_like(t_te)]\n",
    "rf_s.fit(X_s_tr, y_tr)\n",
    "cate_S = rf_s.predict(X_s_te_1) - rf_s.predict(X_s_te_0)\n",
    "\n",
    "# --- X-learner ---\n",
    "# Step 1: use T-learner mu0/mu1 from above to form pseudo-outcomes\n",
    "D1 = y_tr[t_tr==1] - rf_t0.predict(X_tr[t_tr==1])   # for treated\n",
    "D0 = rf_t1.predict(X_tr[t_tr==0]) - y_tr[t_tr==0]   # for control\n",
    "\n",
    "rf_x1 = RandomForestRegressor(n_estimators=200, random_state=3, n_jobs=-1)\n",
    "rf_x0 = RandomForestRegressor(n_estimators=200, random_state=4, n_jobs=-1)\n",
    "rf_x1.fit(X_tr[t_tr==1], D1)\n",
    "rf_x0.fit(X_tr[t_tr==0], D0)\n",
    "\n",
    "# Propensity for weighting (simple logistic on train split)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_tr, t_tr)\n",
    "p_te = np.clip(lr.predict_proba(X_te)[:,1], 1e-3, 1-1e-3)\n",
    "\n",
    "tau1 = rf_x1.predict(X_te)   # estimate if treated\n",
    "tau0 = rf_x0.predict(X_te)   # estimate if control\n",
    "cate_X = p_te * tau0 + (1 - p_te) * tau1\n",
    "\n",
    "# Summaries\n",
    "def summarize(arr, name):\n",
    "    q = np.quantile(arr, [0.05, 0.25, 0.5, 0.75, 0.95])\n",
    "    print(f\"{name} CATE ~ mean={arr.mean():.3f}, median={q[2]:.3f}, IQR=({q[1]:.3f},{q[3]:.3f}), 5-95%: ({q[0]:.3f},{q[4]:.3f})\")\n",
    "\n",
    "summarize(cate_T, \"T-learner\")\n",
    "summarize(cate_S, \"S-learner\")\n",
    "summarize(cate_X, \"X-learner\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(cate_T, bins=50, alpha=0.6, label=\"T-learner\", density=True)\n",
    "plt.hist(cate_S, bins=50, alpha=0.6, label=\"S-learner\", density=True)\n",
    "plt.hist(cate_X, bins=50, alpha=0.6, label=\"X-learner\", density=True)\n",
    "plt.title(\"Estimated CATE distributions (test set)\")\n",
    "plt.xlabel(\"Estimated uplift\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0bd2f",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Targeting by uplift (simple policy)\n",
    "Use CATE scores to target a top fraction of users. Compare average outcomes within **absolutely randomized** test cells if available; in synthetic offline evaluation, we proxy gains by **predicted** uplift and sanity‑check monotonicity across score deciles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976057d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rank by X-learner CATE (often most stable)\n",
    "order = np.argsort(-cate_X)\n",
    "deciles = np.array_split(order, 10)\n",
    "\n",
    "avg_cate_by_decile = [cate_X[idx].mean() for idx in deciles]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1,11), avg_cate_by_decile, marker=\"o\")\n",
    "plt.title(\"Average predicted uplift by decile (X-learner)\")\n",
    "plt.xlabel(\"Decile (1=highest uplift)\")\n",
    "plt.ylabel(\"Mean predicted uplift\")\n",
    "plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "print(\"Top-10% mean predicted uplift:\", avg_cate_by_decile[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d96fa9",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Key takeaways & next steps\n",
    "- **Design > analysis:** randomize where possible; stratify by cohorts; track SRM; use CUPED for precision.  \n",
    "- **Back‑door vs IV:** control observed confounders; if unobservables remain but an instrument exists, 2SLS helps.  \n",
    "- **Exposure bias:** fix via design (eligibility caps/strata) or analysis (IPW, front‑door, dose models).  \n",
    "- **CATE:** meta‑learners with Random Forests give powerful **nonlinear heterogeneity** with minimal dependencies.  \n",
    "- **Next:** add honest splitting, cross‑fitting, doubly‑robust learners (e.g., `EconML` CausalForestDML / DR Learners), multiple‑testing control for many segments, and online uplift experiments (interleaving, Thompson sampling).\n",
    "\n",
    "---\n",
    "\n",
    "### Repro notes\n",
    "- This notebook avoids non‑standard packages so it’s portable.  \n",
    "- True causal forests are available in `econml` (`CausalForestDML`) or `grf` (R). Swap our meta‑learners with those for state‑of‑the‑art CATE.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
