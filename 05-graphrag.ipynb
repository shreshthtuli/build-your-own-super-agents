{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Knowledge Graphs and GraphRAG\n",
    "\n",
    "So far in this course, we‚Äôve explored **traditional RAG (Retrieval-Augmented Generation)** ‚Äî a paradigm where large language models retrieve **unstructured text chunks** from vector databases (like FAISS or LanceDB) and synthesize answers on-the-fly.  \n",
    "\n",
    "While RAG works well for surface-level question answering, it **struggles with structure, reasoning, and relationships**. It treats text as isolated passages ‚Äî not as **entities** linked by meaning or causality.  That‚Äôs where **Knowledge Graphs** and **GraphRAG** step in.\n",
    "\n",
    "## üß† Why Knowledge Graphs?\n",
    "\n",
    "A **Knowledge Graph (KG)** represents knowledge as **nodes (entities)** and **edges (relationships)**, creating a structured and interpretable memory.  \n",
    "In contrast to flat vector retrieval, KGs allow an agent to:\n",
    "\n",
    "- **Reason symbolically** ‚Äî follow explicit paths like *‚ÄúPichu ‚Üí Pikachu ‚Üí Raichu‚Äù*.  \n",
    "- **Disambiguate entities** ‚Äî distinguish *Thunderbolt (move)* vs *Thunderbolt (item)*.  \n",
    "- **Fuse multi-source facts** ‚Äî merging structured and unstructured evidence.  \n",
    "- **Explain answers** ‚Äî show the exact graph edges used in reasoning.\n",
    "\n",
    "This yields an AI system that is not only more **precise** but also **auditable** and **less hallucinatory**.\n",
    "\n",
    "**GraphRAG** blends the strengths of retrieval and structured reasoning:\n",
    "1. **Retrieve** relevant context ‚Üí turn it into triples (`(subject, predicate, object)`).\n",
    "2. **Store / update** these triples in a **graph backend** (persistent memory).  \n",
    "3. **Reason on the graph** to answer complex or multi-hop queries.\n",
    "\n",
    "In essence, **GraphRAG = RAG + Knowledge Graph Reasoning**. Instead of searching documents, we query the graph ‚Äî traversing relationships explicitly.\n",
    "\n",
    "\n",
    "## üß© Enter Graphiti + FalkorDB\n",
    "\n",
    "We‚Äôll use the [**Graphiti**](https://github.com/getzep/graphiti) library ‚Äî a lightweight, production-grade framework for building **temporal knowledge graphs** that integrate directly with LLMs.  \n",
    "\n",
    "**FalkorDB** is a **high-performance graph database** built on Redis, which we use as the backend for Graphiti. It combines the **speed of in-memory databases** with **Cypher-style graph queries**, making it perfect for real-time AI agents that need to evolve their graph dynamically.\n",
    "\n",
    "Graphiti uses structured outputs from LLMs to **extract triples**, **store them as graph edges**, and **enable reasoning** through its built-in query APIs and MCP server. Together, Graphiti + FalkorDB create the ideal playground for **GraphRAG agents** ‚Äî ones that can remember, reason, and adapt.\n",
    "\n",
    "However, let's first start with what it takes to create graphical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97987497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math\n",
    "from typing import List, Optional, Literal, Tuple, Dict\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  # expects OPENROUTER_API_KEY in your environment\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "CHAT_MODEL = \"openrouter:google/gemini-2.5-flash\"\n",
    "EMBED_MODEL = \"openai/text-embedding-3-large\"\n",
    "\n",
    "openai = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "EPISODES = [\n",
    "    \"\"\"Ash meets a timid Pichu that later evolves into Pikachu using friendship.\n",
    "       Pikachu is an Electric-type and often uses Thunderbolt against Team Rocket.\"\"\",\n",
    "    \"\"\"During a gym battle, Pikachu faces a Ground-type opponent and struggles due to type disadvantage.\n",
    "       Raichu appears later as Pikachu's evolution with a Thunder Stone.\"\"\",\n",
    "    \"\"\"Pikachu practices Quick Attack in the forest. Trainers discuss that Electric resists Flying and Steel.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cf3e2",
   "metadata": {},
   "source": [
    "### üß© Define the Schema and Create a Triple-Extraction Agent\n",
    "\n",
    "Before we can build a knowledge graph, we need to define **what relationships are allowed**.  \n",
    "We‚Äôll describe our Pok√©mon world using a small, fixed schema of predicates such as:\n",
    "\n",
    "- `HAS_TYPE` ‚Äî connects a Pok√©mon to its elemental type  \n",
    "- `EVOLVES_TO` ‚Äî shows evolution paths  \n",
    "- `NEEDS_ITEM` ‚Äî evolution dependency (e.g., Thunder Stone)  \n",
    "- `LEARNS_MOVE` ‚Äî captures learnable moves  \n",
    "- `WEAK_AGAINST`, `RESISTS` ‚Äî for type matchups  \n",
    "\n",
    "Using this schema, we‚Äôll create two **Pydantic models**:\n",
    "1. `Triple` ‚Äî represents one edge (`subject`, `predicate`, `object`)  \n",
    "2. `BuildKGResult` ‚Äî wraps the list of extracted entities and triples  \n",
    "\n",
    "Finally, we‚Äôll define a **PydanticAI Agent** called `builder` that takes raw episode text and returns structured triples according to our schema.  \n",
    "This mimics how an information-extraction LLM in Graphiti works under the hood ‚Äî but here we do it manually for clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a620fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "\n",
    "ValidPredicates = Literal[\n",
    "    \"HAS_TYPE\", \"EVOLVES_TO\", \"NEEDS_ITEM\", \"LEARNS_MOVE\", \"WEAK_AGAINST\", \"RESISTS\"\n",
    "]\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    subject: str\n",
    "    predicate: ValidPredicates\n",
    "    object: str\n",
    "    fact: Optional[str] = None\n",
    "    confidence: float = Field(0.9, ge=0.0, le=1.0)\n",
    "\n",
    "class BuildKGResult(BaseModel):\n",
    "    entities: List[str]\n",
    "    triples: List[Triple]\n",
    "\n",
    "builder = Agent[None, BuildKGResult](\n",
    "    model=CHAT_MODEL,\n",
    "    system_prompt=(\n",
    "        \"You are a precise IE system. Extract schema-conformant triples ONLY from the provided episode text.\\n\"\n",
    "        \"Schema:\\n\"\n",
    "        \"- Entities: Pokemon/Type/Move/Item are plain strings (e.g., 'Pikachu', 'Electric', 'Thunderbolt', 'Thunder Stone').\\n\"\n",
    "        \"- Relations: HAS_TYPE(Pokemon‚ÜíType), EVOLVES_TO(Pokemon‚ÜíPokemon), NEEDS_ITEM(Pokemon‚ÜíItem), \"\n",
    "        \"LEARNS_MOVE(Pokemon‚ÜíMove), WEAK_AGAINST(Pokemon‚ÜíType), RESISTS(Pokemon‚ÜíType)\\n\"\n",
    "        \"Return a JSON with 'entities' and 'triples'.\"\n",
    "    ),\n",
    "    output_type=BuildKGResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f842a",
   "metadata": {},
   "source": [
    "### üï∏Ô∏è Build a Minimal In-Memory Graph\n",
    "\n",
    "Now that we can extract structured triples from episode text, we need a simple data structure to **store them as a graph** ‚Äî with **nodes** and **edges**.\n",
    "\n",
    "Here we‚Äôll implement a lightweight `MiniGraph` class that:\n",
    "- Keeps track of **nodes** (unique entity names like *Pikachu*, *Electric*, *Thunderbolt*)  \n",
    "- Stores **edges** (`subject ‚Üí predicate ‚Üí object`) as `Edge` dataclasses  \n",
    "- Provides helper methods to generate text corpora of nodes and edges for embedding later\n",
    "\n",
    "We‚Äôll also use `logfire` to instrument PydanticAI for observability and apply `nest_asyncio` so that async agents can run smoothly inside notebooks.\n",
    "\n",
    "Finally, we‚Äôll loop through our Pok√©mon episode texts, extract triples using the `builder` agent, and populate the graph.  \n",
    "This gives us an interpretable **knowledge graph memory** ‚Äî before we move on to embedding and semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94e414aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-eu.pydantic.dev/shreshthtuli/agenticai\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-eu.pydantic.dev/shreshthtuli/agenticai</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=557004;https://logfire-eu.pydantic.dev/shreshthtuli/agenticai\u001b\\\u001b[4;36mhttps://logfire-eu.pydantic.dev/shreshthtuli/agenticai\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:51:25.869 builder run\n",
      "19:51:25.870   chat google/gemini-2.5-flash\n",
      "19:51:27.785 builder run\n",
      "19:51:27.785   chat google/gemini-2.5-flash\n",
      "19:51:29.862 builder run\n",
      "19:51:29.862   chat google/gemini-2.5-flash\n",
      "Nodes: 10\n",
      "Edges: 9\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import logfire\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logfire.configure()\n",
    "logfire.instrument_pydantic_ai()\n",
    "\n",
    "@dataclass\n",
    "class Edge:\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object: str\n",
    "    fact: str = \"\"\n",
    "    confidence: float = 1.0\n",
    "\n",
    "class MiniGraph:\n",
    "    def __init__(self):\n",
    "        self.nodes = set()\n",
    "        self.edges: List[Edge] = []\n",
    "        # embedding indexes\n",
    "        self.node_texts: List[str] = []    # e.g., node labels like \"Pikachu\"\n",
    "        self.node_vecs: List[List[float]] = []\n",
    "        self.edge_texts: List[str] = []    # e.g., \"(Pikachu)-[HAS_TYPE]->(Electric)\"\n",
    "        self.edge_vecs: List[List[float]] = []\n",
    "\n",
    "    def add_triple(self, t: Triple):\n",
    "        self.nodes.add(t.subject); self.nodes.add(t.object)\n",
    "        self.edges.append(Edge(t.subject, t.predicate, t.object, t.fact or \"\", t.confidence))\n",
    "\n",
    "    def node_corpus(self) -> List[str]:\n",
    "        return sorted(self.nodes)\n",
    "\n",
    "    def edge_corpus(self) -> List[str]:\n",
    "        return [f\"({e.subject})-[{e.predicate}]->({e.object}) :: {e.fact}\" for e in self.edges]\n",
    "\n",
    "GRAPH = MiniGraph()\n",
    "\n",
    "def add_episode_to_graph(text: str):\n",
    "    res = builder.run_sync(f\"Episode:\\n{text}\").output\n",
    "    for t in res.triples:\n",
    "        GRAPH.add_triple(t)\n",
    "    return res\n",
    "\n",
    "for ep in EPISODES:\n",
    "    add_episode_to_graph(ep)\n",
    "\n",
    "print(\"Nodes:\", len(GRAPH.nodes))\n",
    "print(\"Edges:\", len(GRAPH.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0871e",
   "metadata": {},
   "source": [
    "Let's see what graph was generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf2a3691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üï∏Ô∏è Knowledge Graph Summary\n",
      "Nodes (10): Electric, Flying, Ground, Pichu, Pikachu, Quick Attack, Raichu, Steel, Thunder Stone, Thunderbolt\n",
      "\n",
      "Edges (9):\n",
      "  (Pichu) -[EVOLVES_TO]-> (Pikachu)  | fact: Pichu that later evolves into Pikachu using friendship.  [conf=0.90]\n",
      "  (Pikachu) -[HAS_TYPE]-> (Electric)  | fact: Pikachu is an Electric-type  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Thunderbolt)  | fact: Pikachu is an Electric-type and often uses Thunderbolt against Team Rocket.  [conf=0.90]\n",
      "  (Pikachu) -[WEAK_AGAINST]-> (Ground)  [conf=0.90]\n",
      "  (Pikachu) -[EVOLVES_TO]-> (Raichu)  [conf=0.90]\n",
      "  (Pikachu) -[NEEDS_ITEM]-> (Thunder Stone)  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Quick Attack)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Flying)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Steel)  [conf=0.90]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def pretty_print_graph(graph: MiniGraph):\n",
    "    print(f\"\\nüï∏Ô∏è Knowledge Graph Summary\")\n",
    "    print(f\"Nodes ({len(graph.nodes)}): {', '.join(sorted(graph.nodes))}\\n\")\n",
    "    print(f\"Edges ({len(graph.edges)}):\")\n",
    "    for e in graph.edges:\n",
    "        print(f\"  ({e.subject}) -[{e.predicate}]-> ({e.object})\"\n",
    "              + (f\"  | fact: {e.fact}\" if e.fact else \"\")\n",
    "              + (f\"  [conf={e.confidence:.2f}]\" if e.confidence != 1.0 else \"\"))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "pretty_print_graph(GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f5033b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:51:41.360 builder run\n",
      "19:51:41.360   chat google/gemini-2.5-flash\n",
      "19:51:43.262 New edge added: ('Pikachu', 'RESISTS', 'Flying')\n",
      "19:51:43.262 New edge added: ('Pikachu', 'RESISTS', 'Steel')\n",
      "Iteration 1: added 2 new edges. Total now 11.\n",
      "19:51:43.262 builder run\n",
      "19:51:43.262   chat google/gemini-2.5-flash\n",
      "19:51:44.393 New edge added: ('Pikachu', 'RESISTS', 'Flying')\n",
      "19:51:44.393 New edge added: ('Pikachu', 'RESISTS', 'Steel')\n",
      "Iteration 2: added 0 new edges. Total now 11.\n",
      "No new edges found after iteration 2. Stopping reflection.\n",
      "\n",
      "üï∏Ô∏è Knowledge Graph Summary\n",
      "Nodes (10): Electric, Flying, Ground, Pichu, Pikachu, Quick Attack, Raichu, Steel, Thunder Stone, Thunderbolt\n",
      "\n",
      "Edges (11):\n",
      "  (Pichu) -[EVOLVES_TO]-> (Pikachu)  | fact: Pichu that later evolves into Pikachu using friendship.  [conf=0.90]\n",
      "  (Pikachu) -[HAS_TYPE]-> (Electric)  | fact: Pikachu is an Electric-type  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Thunderbolt)  | fact: Pikachu is an Electric-type and often uses Thunderbolt against Team Rocket.  [conf=0.90]\n",
      "  (Pikachu) -[WEAK_AGAINST]-> (Ground)  [conf=0.90]\n",
      "  (Pikachu) -[EVOLVES_TO]-> (Raichu)  [conf=0.90]\n",
      "  (Pikachu) -[NEEDS_ITEM]-> (Thunder Stone)  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Quick Attack)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Flying)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Steel)  [conf=0.90]\n",
      "  (Pikachu) -[RESISTS]-> (Flying)  | fact: Pikachu is Electric-type, and Electric resists Flying  [conf=0.50]\n",
      "  (Pikachu) -[RESISTS]-> (Steel)  | fact: Pikachu is Electric-type, and Electric resists Steel  [conf=0.50]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy \n",
    "\n",
    "def reflect_and_expand(graph: MiniGraph, max_iters: int = 3):\n",
    "    prev_edge_count = -1\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iters:\n",
    "        iteration += 1\n",
    "        current_count = len(graph.edges)\n",
    "        if current_count == prev_edge_count:\n",
    "            print(f\"No new edges found after iteration {iteration-1}. Stopping reflection.\")\n",
    "            break\n",
    "\n",
    "        prev_edge_count = current_count\n",
    "        graph_state = json.dumps([e.__dict__ for e in graph.edges], indent=2)\n",
    "\n",
    "        # Ask the same builder agent if new relationships can be added\n",
    "        prompt = (\n",
    "            f\"Here is the current knowledge graph:\\n{graph_state}\\n\\n\"\n",
    "            \"Reflect on it and see if any *implicit* or *missing* relationships \"\n",
    "            \"can be derived from this graph. Add only valid new triples, if any. \"\n",
    "            \"Return empty if nothing new can be inferred.\"\n",
    "        )\n",
    "\n",
    "        reflection = builder.run_sync(prompt).output\n",
    "\n",
    "        # Add new edges (if any)\n",
    "        added = 0\n",
    "        for t in reflection.triples:\n",
    "            logfire.info(f\"New edge added: {(t.subject, t.predicate, t.object)}\")\n",
    "            key = (t.subject, t.predicate, t.object)\n",
    "            existing = {(e.subject, e.predicate, e.object) for e in graph.edges}\n",
    "            if key not in existing:\n",
    "                graph.add_triple(t)\n",
    "                added += 1\n",
    "\n",
    "        print(f\"Iteration {iteration}: added {added} new edges. Total now {len(graph.edges)}.\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "NEWGRAPH = reflect_and_expand(deepcopy(GRAPH))\n",
    "pretty_print_graph(NEWGRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ee95e",
   "metadata": {},
   "source": [
    "In this example, our **builder agent** initially extracted direct facts from the Pok√©mon episodes ‚Äî things like *‚ÄúPikachu evolves to Raichu‚Äù* or *‚ÄúPikachu has type Electric.‚Äù*  \n",
    "\n",
    "When we introduced the **reflection loop**, the agent began to **review its own graph output** and infer **missing or implicit relations**. For instance, it noticed that Pikachu also **resists Flying and Steel** ‚Äî facts implied by its Electric typing but not explicitly mentioned in the text.\n",
    "\n",
    "This reflective step acts as a lightweight **self-consistency check**:\n",
    "- It helps the model **fill small gaps** in knowledge by reasoning over the structure it already built.  \n",
    "- It can correct omissions or low-confidence facts without requiring another dataset.  \n",
    "- It converges automatically ‚Äî once the graph stabilizes (no new edges are added), the loop stops.\n",
    "\n",
    "In a larger system, this is the foundation of **agentic knowledge refinement** ‚Äî the same principle used by **Graphiti** and other **GraphRAG** frameworks to keep the knowledge graph both **complete** and **consistent** over time.\n",
    "\n",
    "### üéØ Embedding and Semantic Search\n",
    "\n",
    "Now that our mini knowledge graph is built and refined, the next step is to make it **searchable**. We‚Äôll embed both **nodes** (entity names) and **edges** (relationships) into vector space using the **OpenRouter embedding API** (`text-embedding-3-large` by OpenAI, accessed via OpenRouter).\n",
    "\n",
    "This lets us perform **semantic search** over the graph ‚Äî so instead of keyword lookups, we can find conceptually related entities and relationships.\n",
    "\n",
    "In this section:\n",
    "1. We define helper functions to **embed** text and **compute cosine similarity**.  \n",
    "2. Build vector indexes for all nodes and edges.  \n",
    "3. Implement simple **search functions** that return the top-K most semantically similar nodes or edges for any query.\n",
    "\n",
    "This is conceptually similar to what happens in **traditional RAG**, except here we are embedding **graph elements** instead of text chunks ‚Äî a key building block for **GraphRAG** reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efde9c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top nodes for 'Pikachu evolution item':\n",
      "[('Pikachu', 0.6038109820985103),\n",
      " ('Pichu', 0.5137344454239156),\n",
      " ('Raichu', 0.49602330682813606),\n",
      " ('Thunder Stone', 0.4325935945057776),\n",
      " ('Quick Attack', 0.34751407732015965)]\n",
      "Top edges for 'type disadvantage against Ground':\n",
      "[('(Pikachu)-[WEAK_AGAINST]->(Ground) :: ', 0.6187038417597363),\n",
      " ('(Electric)-[RESISTS]->(Flying) :: ', 0.4096363073497873),\n",
      " ('(Electric)-[RESISTS]->(Steel) :: ', 0.38052656641427385),\n",
      " ('(Pikachu)-[LEARNS_MOVE]->(Thunderbolt) :: Pikachu is an Electric-type and '\n",
      "  'often uses Thunderbolt against Team Rocket.',\n",
      "  0.33758124041925275),\n",
      " ('(Pikachu)-[HAS_TYPE]->(Electric) :: Pikachu is an Electric-type',\n",
      "  0.31840167619153525)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def embed_texts(texts: List[str]) -> List[List[float]]:\n",
    "    if not texts:\n",
    "        return []\n",
    "    resp = openai.embeddings.create(model=EMBED_MODEL, input=texts)\n",
    "    return [d.embedding for d in resp.data]\n",
    "\n",
    "def normalize(v: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.dot(normalize(a), normalize(b)))\n",
    "\n",
    "def build_vector_indexes():\n",
    "    GRAPH.node_texts = GRAPH.node_corpus()\n",
    "    GRAPH.node_vecs = embed_texts(GRAPH.node_texts)\n",
    "    GRAPH.edge_texts = GRAPH.edge_corpus()\n",
    "    GRAPH.edge_vecs = embed_texts(GRAPH.edge_texts)\n",
    "\n",
    "def search_nodes(query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
    "    if not GRAPH.node_texts:\n",
    "        return []\n",
    "    qv = embed_texts([query])[0]\n",
    "    sims = [cosine_sim(np.array(qv), np.array(v)) for v in GRAPH.node_vecs]\n",
    "    ranked = sorted(zip(GRAPH.node_texts, sims), key=lambda x: x[1], reverse=True)\n",
    "    return ranked[:k]\n",
    "\n",
    "def search_edges(query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
    "    if not GRAPH.edge_texts:\n",
    "        return []\n",
    "    qv = embed_texts([query])[0]\n",
    "    sims = [cosine_sim(np.array(qv), np.array(v)) for v in GRAPH.edge_vecs]\n",
    "    ranked = sorted(zip(GRAPH.edge_texts, sims), key=lambda x: x[1], reverse=True)\n",
    "    return ranked[:k]\n",
    "\n",
    "build_vector_indexes()\n",
    "\n",
    "print(\"Top nodes for 'Pikachu evolution item':\")\n",
    "pprint(search_nodes(\"Pikachu evolution item\"))\n",
    "\n",
    "print(\"Top edges for 'type disadvantage against Ground':\")\n",
    "pprint(search_edges(\"type disadvantage against Ground\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ac2bc",
   "metadata": {},
   "source": [
    "## üß© Graphiti abstraction\n",
    "\n",
    "All these embedding and search operations are automatically handled inside **Graphiti**.  \n",
    "It provides:\n",
    "- Configurable **embedders** and **cross-encoders** for reranking  \n",
    "- Persistent **vector indexes** linked to graph nodes  \n",
    "- Integration with real graph backends (e.g., **FalkorDB**, **Neo4j**)  \n",
    "- APIs to search, rank, and traverse the graph directly  \n",
    "\n",
    "So while we‚Äôre writing these utilities manually here to understand the mechanics, in the next section we‚Äôll switch to **Graphiti**, which abstracts away all this boilerplate and provides a much more powerful, production-ready interface.\n",
    "\n",
    "Let's first create the FalkorDB as a backend for Graphiti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "552be5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing running container: zen_shtern (ID: fd62a6f12e2b)\n",
      "Container is already running. Skipping startup.\n"
     ]
    }
   ],
   "source": [
    "from graphiti_core import Graphiti\n",
    "from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient\n",
    "from graphiti_core.llm_client.openai_client import OpenAIClient\n",
    "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig\n",
    "from graphiti_core.driver.falkordb_driver import FalkorDriver\n",
    "from graphiti_core.llm_client.config import LLMConfig\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from src.flakordb_setup import run_falkordb\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "run_falkordb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f08d61",
   "metadata": {},
   "source": [
    "In **Graphiti**, these three components play the same roles as in a traditional RAG pipeline ‚Äî but for **graph-based reasoning** instead of plain text retrieval.\n",
    "\n",
    "1. **LLM Client (`OpenAIGenericClient`)**  \n",
    "   - This wraps the language model endpoint (in our case, **Gemini 2.5 Flash** via OpenRouter).  \n",
    "   - It‚Äôs used for all generative tasks inside Graphiti ‚Äî such as extracting triples, summarizing nodes, or generating context-aware graph queries.\n",
    "\n",
    "2. **Embedder (`OpenAIEmbedder`)**  \n",
    "   - Similar to the vector embedder in RAG, it converts text, entity names, or relationships into dense embeddings for **semantic similarity search** within the graph.  \n",
    "   - We use `text-embedding-3-large` from OpenAI to create these embeddings, allowing Graphiti to find related nodes or documents efficiently.\n",
    "\n",
    "3. **Cross-Encoder / Re-ranker (`OpenAIRerankerClient`)**  \n",
    "   - After retrieval, multiple candidate nodes or subgraphs may be found.  \n",
    "   - The reranker uses a small LLM to **score and reorder** these candidates based on their semantic relevance to the query, improving precision.  \n",
    "   - This is analogous to the reranking step in advanced RAG setups.\n",
    "\n",
    "Together, these components form the **reasoning and retrieval core** of Graphiti. *The embedder finds relevant graph pieces, the reranker prioritizes them, and the LLM client performs reasoning over the final context.*\n",
    "\n",
    "We shall use [Graphiti's custom entity and edge types](https://help.getzep.com/graphiti/core-concepts/custom-entity-and-edge-types) for our use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5e2e06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphiti_core.utils.maintenance.graph_data_operations import clear_data\n",
    "from src.graphiti_utils import pretty_print\n",
    "from datetime import datetime\n",
    "\n",
    "llm_config = LLMConfig(api_key=os.getenv(\"OPENROUTER_API_KEY\"), \n",
    "                       base_url=\"https://openrouter.ai/api/v1\", \n",
    "                       model=\"openai/gpt-5\",\n",
    "                       small_model=\"openai/gpt-5-mini\")\n",
    "client = OpenAIClient(config=llm_config, reasoning='medium')\n",
    "\n",
    "embedder_config = OpenAIEmbedderConfig(api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "                                       base_url=\"https://openrouter.ai/api/v1\",\n",
    "                                       embedding_model=\"openai/text-embedding-3-large\")\n",
    "embedder = OpenAIEmbedder(embedder_config)\n",
    "\n",
    "reranker = OpenAIRerankerClient(llm_config)\n",
    "\n",
    "driver = FalkorDriver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15965fa2",
   "metadata": {},
   "source": [
    "### üß≠ What is an Ontology (and why it matters for Graph/GraphRAG)?\n",
    "\n",
    "An **ontology** is a formal, shared specification of the **concepts (classes)** in a domain, their **attributes (properties)**, and the **relationships** among them.  \n",
    "In graph terms, it defines:\n",
    "- **Entity types** (e.g., `Pokemon`, `Type`, `Move`, `Item`)\n",
    "- **Attributes** on entities (e.g., `Pokemon.stage`, `Move.power`)\n",
    "- **Relation types** (e.g., `HAS_TYPE`, `EVOLVES_TO`, `LEARNS_MOVE`)\n",
    "- **Domain/Range constraints** (what can connect to what) and sometimes **cardinalities** (e.g., `Pokemon HAS_TYPE Type`)\n",
    "\n",
    "A good ontology:\n",
    "- **Reduces hallucinations** by constraining what can be asserted\n",
    "- **Improves explainability** because answers refer to explicit entities/relations\n",
    "- **Enables reusable reasoning** across tasks (querying, validation, analytics)\n",
    "\n",
    "See more on [FalkorDB's blog](https://www.falkordb.com/blog/understanding-ontologies-knowledge-graph-schemas/).\n",
    "\n",
    "**Pragmatic recipe to design one**\n",
    "1. List **core entities** and the questions you must answer.  \n",
    "2. Define **relations** that connect those entities (domain/range).  \n",
    "3. Add **attributes** needed for reasoning (and keep the rest out).  \n",
    "4. Start small; **iterate** with real data; add constraints as you go.  \n",
    "\n",
    "Allthough ontologies can be created by LLMs like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b0a761ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:33:34.437 ontology_suggester run\n",
      "23:33:34.439   chat google/gemini-2.5-flash\n",
      "=== Ontology Proposal ===\n",
      "{\n",
      "  \"classes\": [\n",
      "    {\n",
      "      \"name\": \"Pokemon\",\n",
      "      \"description\": \"Represents a distinct species of Pok\\u00e9mon.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"Name of the Pokemon\",\n",
      "          \"required\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"stage\",\n",
      "          \"dtype\": \"int\",\n",
      "          \"description\": \"Evolution stage of the Pokemon\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Type\",\n",
      "      \"description\": \"Represents a Pok\\u00e9mon's elemental type.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"Name of the type (e.g., Electric, Ground)\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Move\",\n",
      "      \"description\": \"Represents a combat action a Pok\\u00e9mon can perform.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"Name of the move (e.g., Thunderbolt, Quick Attack)\",\n",
      "          \"required\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"power\",\n",
      "          \"dtype\": \"int\",\n",
      "          \"description\": \"Base power of the move, if applicable\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Item\",\n",
      "      \"description\": \"Represents an item that can be used in the Pok\\u00e9mon world.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"Name of the item (e.g., Thunder Stone)\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"relations\": [\n",
      "    {\n",
      "      \"name\": \"HAS_TYPE\",\n",
      "      \"description\": \"Indicates the elemental type(s) a Pok\\u00e9mon possesses.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Type\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"EVOLVES_TO\",\n",
      "      \"description\": \"Indicates a Pok\\u00e9mon evolves into another Pok\\u00e9mon.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Pokemon\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"NEEDS_ITEM\",\n",
      "      \"description\": \"Indicates a Pok\\u00e9mon needs a specific item for evolution.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Item\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"LEARNS_MOVE\",\n",
      "      \"description\": \"Indicates a Pok\\u00e9mon can learn a particular move.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Move\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"WEAK_AGAINST\",\n",
      "      \"description\": \"Indicates a type is weak against another type (takes super effective damage).\",\n",
      "      \"domain\": \"Type\",\n",
      "      \"range\": \"Type\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"RESISTS\",\n",
      "      \"description\": \"Indicates a type resists another type (takes not very effective damage).\",\n",
      "      \"domain\": \"Type\",\n",
      "      \"range\": \"Type\"\n",
      "    }\n",
      "  ],\n",
      "  \"notes\": \"This ontology captures key details about Pok\\u00e9mon, their types, moves, and evolution items for basic Q&A and reasoning. It is kept minimal and focused on the provided examples.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class OntologyAttribute(BaseModel):\n",
    "    name: str\n",
    "    dtype: Literal[\"string\",\"int\",\"float\",\"bool\",\"datetime\",\"enum\",\"id\"] = \"string\"\n",
    "    description: Optional[str] = None\n",
    "    required: bool = False\n",
    "\n",
    "class OntologyClass(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    attributes: List[OntologyAttribute] = Field(default_factory=list)\n",
    "\n",
    "class OntologyRelation(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    domain: str  # class name\n",
    "    range: str   # class name\n",
    "\n",
    "class OntologyProposal(BaseModel):\n",
    "    classes: List[OntologyClass]\n",
    "    relations: List[OntologyRelation]\n",
    "    notes: Optional[str] = None\n",
    "\n",
    "ontology_suggester = Agent(\n",
    "    model=CHAT_MODEL,\n",
    "    system_prompt=(\n",
    "        \"You are an ontology engineer. Given example domain text, propose a SMALL, \"\n",
    "        \"pragmatic ontology capturing key classes, attributes, and relations. \"\n",
    "        \"Keep it minimal but sufficient for QA and reasoning. Prefer concise names. \"\n",
    "        \"Return structured JSON matching OntologyProposal.\"\n",
    "    ),\n",
    "    output_type=OntologyProposal,\n",
    ")\n",
    "\n",
    "def suggest_ontology_from_examples(texts: List[str]) -> OntologyProposal:\n",
    "    corpus = \"\\n\\n---\\n\\n\".join(texts)\n",
    "    prompt = (\n",
    "        \"Domain examples:\\n\"\n",
    "        f\"{corpus}\\n\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"- Classes should include Pokemon, Type, Move, and Item if present.\\n\"\n",
    "        \"- Add minimal attributes that are useful for Q&A (e.g., power for moves, stage for pokemon).\\n\"\n",
    "        \"- Add relations like HAS_TYPE, EVOLVES_TO, NEEDS_ITEM, LEARNS_MOVE, WEAK_AGAINST, RESISTS.\\n\"\n",
    "        \"- You may add brief descriptions.\\n\"\n",
    "        \"- Keep it compact. Avoid unnecessary ontology.\"\n",
    "    )\n",
    "    return ontology_suggester.run_sync(prompt).output\n",
    "\n",
    "proposal = suggest_ontology_from_examples(EPISODES)\n",
    "\n",
    "print(\"=== Ontology Proposal ===\")\n",
    "print(json.dumps(proposal.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c2e7cb",
   "metadata": {},
   "source": [
    "For our use-case, we define a fixed ontology as follows. \n",
    "\n",
    "We will use [Graphiti's custom entities and edges](https://help.getzep.com/graphiti/core-concepts/custom-entity-and-edge-types) to encode this ontology for our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062df90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphiti_core.utils.bulk_utils import RawEpisode\n",
    "from graphiti_core.nodes import EpisodeType\n",
    "from pathlib import Path\n",
    "import os \n",
    "\n",
    "# Entities\n",
    "class Pokemon(BaseModel):\n",
    "    \"\"\"A Pokemon species or evolutionary form.\"\"\"\n",
    "    stage: Optional[int] = Field(None, description=\"Evolution stage number (e.g., Pichu is 1, Pikachu is 2, Raichu is 3)\")\n",
    "\n",
    "class Type(BaseModel):\n",
    "    \"\"\"Elemental typing such as Electric, Ground, Flying.\"\"\"\n",
    "    category: Optional[str] = Field(None, description=\"Damage class or grouping if applicable\")\n",
    "\n",
    "class Move(BaseModel):\n",
    "    \"\"\"A move a Pokemon can learn or use.\"\"\"\n",
    "    power: Optional[int] = Field(None, description=\"Base power if applicable\")\n",
    "    move_type: Optional[str] = Field(None, description=\"Type of the move, e.g., Electric\")\n",
    "\n",
    "class Item(BaseModel):\n",
    "    \"\"\"An evolution or battle item.\"\"\"\n",
    "    effect: Optional[str] = Field(None, description=\"Short description of the item effect\")\n",
    "\n",
    "# Edges\n",
    "class HasType(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Type\"\"\"\n",
    "    pass\n",
    "\n",
    "class EvolvesTo(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Pokemon\"\"\"\n",
    "    method: Optional[str] = Field(None, description=\"Evolution method (friendship, level, etc.)\")\n",
    "\n",
    "class NeedsItem(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Item\"\"\"\n",
    "    reason: Optional[str] = Field(None, description=\"Why the item is required (e.g., evolve)\")\n",
    "\n",
    "class LearnsMove(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Move\"\"\"\n",
    "    learn_method: Optional[str] = Field(None, description=\"TM/TR/Level-up/etc.\")\n",
    "    level: Optional[int] = Field(None, description=\"Level when learned, if applicable\")\n",
    "\n",
    "class WeakAgainst(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Type\"\"\"\n",
    "    note: Optional[str] = Field(None, description=\"Context note\")\n",
    "\n",
    "class Resists(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Type\"\"\"\n",
    "    note: Optional[str] = Field(None, description=\"Context note\")\n",
    "\n",
    "# Entity and edge registries\n",
    "entity_types: Dict[str, type] = {\n",
    "    \"Pokemon\": Pokemon,\n",
    "    \"Type\": Type,\n",
    "    \"Move\": Move,\n",
    "    \"Item\": Item,\n",
    "}\n",
    "\n",
    "edge_types: Dict[str, type] = {\n",
    "    \"HAS_TYPE\": HasType,\n",
    "    \"EVOLVES_TO\": EvolvesTo,\n",
    "    \"NEEDS_ITEM\": NeedsItem,\n",
    "    \"LEARNS_MOVE\": LearnsMove,\n",
    "    \"WEAK_AGAINST\": WeakAgainst,\n",
    "    \"RESISTS\": Resists,\n",
    "}\n",
    "\n",
    "# Which edge types are allowed between which entity pairs\n",
    "edge_type_map: Dict[Tuple[str, str], List[str]] = {\n",
    "    (\"Pokemon\", \"Type\"): [\"HAS_TYPE\", \"WEAK_AGAINST\", \"RESISTS\"],\n",
    "    (\"Pokemon\", \"Pokemon\"): [\"EVOLVES_TO\"],\n",
    "    (\"Pokemon\", \"Item\"): [\"NEEDS_ITEM\"],\n",
    "    (\"Pokemon\", \"Move\"): [\"LEARNS_MOVE\"],\n",
    "}\n",
    "\n",
    "graphiti = Graphiti(graph_driver=driver, llm_client=client, embedder=embedder, cross_encoder=reranker)\n",
    "\n",
    "await clear_data(graphiti.driver)\n",
    "await graphiti.build_indices_and_constraints(delete_existing=True)\n",
    "\n",
    "DB_FILES = \"data/pokemon_md/\"\n",
    "\n",
    "episodes = []\n",
    "for filename in os.listdir(DB_FILES)[:1]:\n",
    "    episodes.append(Path(DB_FILES + filename).read_text(encoding='utf-8'))\n",
    "\n",
    "graphiti_episodes = [RawEpisode(name=f\"Episode {i+1}\",\n",
    "                                content=ep,\n",
    "                                source_description=\"episode\",\n",
    "                                source=EpisodeType.text,\n",
    "                                reference_time=datetime.now())\n",
    "                            for i, ep in enumerate(episodes)]\n",
    "\n",
    "await graphiti.add_episode_bulk(graphiti_episodes, \n",
    "                                group_id=\"pokemon_data_tmp\",\n",
    "                                entity_types=entity_types,\n",
    "                                edge_types=edge_types,\n",
    "                                edge_type_map=edge_type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e943c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await graphiti.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d58018b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for: 'Pikachu evolution item'\n",
      "\n",
      "Search Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'group_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\\\_'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'79de5f46-96a9-4707-8414-2f48d2dc2cc6'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">934315</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'RELATES_TO'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fact'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Pikachu has type electric'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'episodes'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'5879af07-b064-4073-9ab1-3fbd65219e6e'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'expired_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'valid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384582</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'invalid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'uuid'\u001b[0m: \u001b[32m'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'group_id'\u001b[0m: \u001b[32m'\\\\_'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'source_node_uuid'\u001b[0m: \u001b[32m'79de5f46-96a9-4707-8414-2f48d2dc2cc6'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'target_node_uuid'\u001b[0m: \u001b[32m'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'created_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m934315\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'RELATES_TO'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'fact'\u001b[0m: \u001b[32m'Pikachu has type electric'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'episodes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'5879af07-b064-4073-9ab1-3fbd65219e6e'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'expired_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'valid_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m21\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m384582\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'invalid_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for: 'type disadvantage against Ground'\n",
      "\n",
      "Search Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'group_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\\\_'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'79de5f46-96a9-4707-8414-2f48d2dc2cc6'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">934315</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'RELATES_TO'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fact'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Pikachu has type electric'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'episodes'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'5879af07-b064-4073-9ab1-3fbd65219e6e'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'expired_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'valid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384582</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'invalid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'uuid'\u001b[0m: \u001b[32m'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'group_id'\u001b[0m: \u001b[32m'\\\\_'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'source_node_uuid'\u001b[0m: \u001b[32m'79de5f46-96a9-4707-8414-2f48d2dc2cc6'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'target_node_uuid'\u001b[0m: \u001b[32m'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'created_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m934315\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'RELATES_TO'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'fact'\u001b[0m: \u001b[32m'Pikachu has type electric'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'episodes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'5879af07-b064-4073-9ab1-3fbd65219e6e'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'expired_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'valid_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m21\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m384582\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'invalid_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nSearching for: 'Pikachu evolution item'\")\n",
    "results = await graphiti.search('Pikachu evolution item')\n",
    "\n",
    "print('\\nSearch Results:')\n",
    "for result in results[:2]:\n",
    "    pretty_print(result)\n",
    "\n",
    "print(\"\\nSearching for: 'type disadvantage against Ground'\")\n",
    "results = await graphiti.search('type disadvantage against Ground')\n",
    "\n",
    "print('\\nSearch Results:')\n",
    "for result in results[:2]:\n",
    "    pretty_print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema: Entities & Relationships\n",
    "\n",
    "We‚Äôll constrain the LLM to produce **triples** under a small ontology.  \n",
    "This reduces hallucinations and keeps the graph clean.\n",
    "\n",
    "**Entities**\n",
    "- `Pokemon(name)`\n",
    "- `Type(name)`\n",
    "- `Move(name)`\n",
    "- `Item(name)`\n",
    "\n",
    "**Relationships (directed)**\n",
    "- `HAS_TYPE(Pokemon ‚Üí Type)`\n",
    "- `EVOLVES_TO(Pokemon ‚Üí Pokemon)`\n",
    "- `NEEDS_ITEM(Pokemon ‚Üí Item)` *(for evolutions that need an item)*\n",
    "- `LEARNS_MOVE(Pokemon ‚Üí Move)`\n",
    "- `WEAK_AGAINST(Pokemon ‚Üí Type)`\n",
    "- `RESISTS(Pokemon ‚Üí Type)`\n",
    "\n",
    "We‚Äôll create **Pydantic models** for the structured output the builder agent must return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "ValidPredicates = Literal[\n",
    "    \"HAS_TYPE\", \"EVOLVES_TO\", \"NEEDS_ITEM\", \"LEARNS_MOVE\", \"WEAK_AGAINST\", \"RESISTS\"\n",
    "]\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    subject: str = Field(description=\"Entity name (e.g., 'Pikachu')\")\n",
    "    predicate: ValidPredicates\n",
    "    object: str = Field(description=\"Entity name (e.g., 'Electric')\")\n",
    "    fact: Optional[str] = Field(default=None, description=\"Optional natural language gloss for the edge\")\n",
    "    # optional metadata\n",
    "    confidence: float = Field(ge=0.0, le=1.0, default=0.9)\n",
    "\n",
    "class BuildKGResult(BaseModel):\n",
    "    entities: List[str] = Field(description=\"All entity names referenced in triples\")\n",
    "    triples: List[Triple]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KG Builder Agent (with self‚Äëreflection)\n",
    "\n",
    "We create two agents:\n",
    "1. **Builder** ‚Äî extracts **schema‚Äëvalid triples** for a user query, constrained to our tiny dataset.\n",
    "2. **Critic** ‚Äî validates the builder‚Äôs output for **schema, consistency, and data grounding**; suggests a corrected set if needed.\n",
    "\n",
    "We‚Äôll run a simple **reflect‚Äërevise loop** up to 2 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "model = OpenAIModel(model=MODEL)\n",
    "\n",
    "builder = Agent[None, BuildKGResult](\n",
    "    model=model,\n",
    "    system_prompt=(\n",
    "        \"You are a strict KG builder. Extract schema-conformant triples ONLY from the provided Pikachu dataset. \"\n",
    "        \"Never invent new pokemon, types, or moves. The schema is:\\n\"\n",
    "        \"- Entities: Pokemon, Type, Move, Item (use names as strings)\\n\"\n",
    "        \"- Rels: HAS_TYPE(Pokemon‚ÜíType), EVOLVES_TO(Pokemon‚ÜíPokemon), NEEDS_ITEM(Pokemon‚ÜíItem), \"\n",
    "        \"LEARNS_MOVE(Pokemon‚ÜíMove), WEAK_AGAINST(Pokemon‚ÜíType), RESISTS(Pokemon‚ÜíType)\\n\"\n",
    "        \"Return entities + triples as structured JSON. Keep subjects/objects as plain names.\"\n",
    "    ),\n",
    "    result_type=BuildKGResult,\n",
    ")\n",
    "\n",
    "class Critique(BaseModel):\n",
    "    ok: bool\n",
    "    reasons: List[str] = []\n",
    "    corrected: Optional[BuildKGResult] = None\n",
    "\n",
    "critic = Agent[BuildKGResult, Critique](\n",
    "    model=model,\n",
    "    system_prompt=(\n",
    "        \"You are a KG critic. Given a candidate BuildKGResult and the Pikachu dataset, verify:\\n\"\n",
    "        \"1) predicates are from the allowed set, 2) all entities appear in dataset, 3) no contradictions, \"\n",
    "        \"4) triples grounded in data. If any problem, set ok=false and return a corrected BuildKGResult.\"\n",
    "    ),\n",
    "    deps_type=BuildKGResult,  # the input to the agent\n",
    "    result_type=Critique,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_entities() -> set:\n",
    "    names = set()\n",
    "    for p in PIKACHU_DATA[\"pokemon\"]:\n",
    "        names.add(p[\"name\"])\n",
    "        for t in p[\"types\"]:\n",
    "            names.add(t)\n",
    "        for a in p[\"abilities\"]:\n",
    "            names.add(a)  # we won't use Ability as an entity, but keep for checks\n",
    "        for w in p[\"weak_against\"]:\n",
    "            names.add(w)\n",
    "        for r in p[\"resists\"]:\n",
    "            names.add(r)\n",
    "        if p[\"evolves_to\"]:\n",
    "            names.add(p[\"evolves_to\"])\n",
    "        if p[\"evolution_item\"]:\n",
    "            names.add(p[\"evolution_item\"])\n",
    "    for m in PIKACHU_DATA[\"moves\"]:\n",
    "        names.add(m[\"name\"]); names.add(m[\"type\"])\n",
    "    return names\n",
    "\n",
    "ALL_KNOWN = dataset_entities()\n",
    "\n",
    "def seed_moves_for(pokemon_name: str) -> List[str]:\n",
    "    # For demo, give a couple of canonical moves\n",
    "    base = {\n",
    "        \"Pichu\": [\"Thunder Wave\", \"Quick Attack\"],\n",
    "        \"Pikachu\": [\"Thunderbolt\", \"Quick Attack\"],\n",
    "        \"Raichu\": [\"Thunderbolt\"]\n",
    "    }\n",
    "    return base.get(pokemon_name, [])\n",
    "\n",
    "def build_kg_for_query(query: str, max_reflections: int = 2) -> BuildKGResult:\n",
    "    # 1) Initial draft\n",
    "    draft = builder.run_sync(f\"Query: {query}\\nDataset (JSON): {json.dumps(PIKACHU_DATA)}\").output\n",
    "\n",
    "    # 2) Critique loop\n",
    "    current = draft\n",
    "    for i in range(max_reflections):\n",
    "        critique = critic.run_sync(\n",
    "            deps=current,\n",
    "            user_message=f\"Check this candidate against dataset. Return ok and corrected if needed.\"\n",
    "        ).output\n",
    "        if critique.ok:\n",
    "            return current\n",
    "        if critique.corrected is not None:\n",
    "            current = critique.corrected\n",
    "    return current\n",
    "\n",
    "# quick smoke test\n",
    "res = build_kg_for_query(\"How does Pikachu evolve and what item is needed? Also list its type and a typical move.\")\n",
    "print(\"Triples:\", len(res.triples))\n",
    "print(res.triples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Persisting to Graphiti\n",
    "\n",
    "We‚Äôll keep a single graph instance for the demo and add triples to it.  \n",
    "If Graphiti is not installed here, we‚Äôll use a small in‚Äëmemory shim with a compatible `add_triplet()` / `neighborhood()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH = Graph()\n",
    "\n",
    "def add_build_result_to_graph(result: BuildKGResult):\n",
    "    for tri in result.triples:\n",
    "        GRAPH.add_triplet(tri.subject, tri.predicate, tri.object, fact=tri.fact or \"\", confidence=tri.confidence)\n",
    "\n",
    "result = build_kg_for_query(\"Create a small KG for Pikachu: type, evolution chain, weaknesses, and one move.\")\n",
    "add_build_result_to_graph(result)\n",
    "print(\"Graph nodes:\", getattr(GRAPH, \"nodes\", \"N/A (backend-managed)\"))\n",
    "try:\n",
    "    print(\"Edges stored:\", len(GRAPH.edges))\n",
    "except Exception:\n",
    "    print(\"Edges stored: backend-managed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KG Answering Agent (with **KG builder tool**)\n",
    "\n",
    "The answering agent can:\n",
    "1. **Query the existing KG** for facts, and\n",
    "2. **If missing**, call the **`build_kg_for_query` tool** to generate & persist the relevant subgraph, then answer.\n",
    "\n",
    "This keeps answers **precise and grounded**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    used_builder: bool = False\n",
    "    evidence: List[Tuple[str, str, str]] = Field(default_factory=list, description=\"subset of triples (s,p,o) used\")\n",
    "\n",
    "answer_agent = Agent[None, Answer](\n",
    "    model=model,\n",
    "    system_prompt=(\n",
    "        \"You answer questions strictly from the Knowledge Graph.\\n\"\n",
    "        \"If the graph does not have sufficient edges to answer, call `make_or_update_graph` tool first, then answer.\\n\"\n",
    "        \"Cite a few (s,p,o) triples used in `evidence`. Be concise and precise.\"\n",
    "    ),\n",
    "    result_type=Answer\n",
    ")\n",
    "\n",
    "@answer_agent.tool\n",
    "def make_or_update_graph(ctx: RunContext[None], query: str) -> str:\n",
    "    \\\"\\\"\\\"Generate/augment the knowledge graph for the user query and persist it; returns a short status string.\\\"\\\"\\\"\n",
    "    result = build_kg_for_query(query)\n",
    "    add_build_result_to_graph(result)\n",
    "    return f\\\"Added {len(result.triples)} triples for query: {query}\\\"\n",
    "\n",
    "def query_graph_edges(subject=None, predicate=None, object=None):\n",
    "    try:\n",
    "        return GRAPH.find_edges(subject=subject, predicate=predicate, object=object)\n",
    "    except Exception:\n",
    "        # If using a real backend, you'd use Graphiti's query API here\n",
    "        return []\n",
    "\n",
    "def answer_with_graph(question: str) -> Answer:\n",
    "    # Optional: pre-check simple availability to guide the LLM\n",
    "    neigh = getattr(GRAPH, \"neighborhood\", None)\n",
    "    hint = \"\"\n",
    "    if neigh is not None:\n",
    "        # naive hint: do we have any neighbors for the main mentioned entity?\n",
    "        if \"Pikachu\" in question:\n",
    "            neighborhood = GRAPH.neighborhood(\"Pikachu\")\n",
    "            if not neighborhood:\n",
    "                hint = \"(Graph appears sparse for Pikachu; consider calling the builder tool.)\"\n",
    "    return answer_agent.run_sync(f\\\"{hint}\\\\nQuestion: {question}\\\").output\n",
    "\n",
    "demo = answer_with_graph(\"What item evolves Pikachu, and what type is Pikachu?\")\n",
    "print(demo.answer, \"\\\\nUsed builder:\", demo.used_builder, \"\\\\nEvidence:\", demo.evidence[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demos\n",
    "\n",
    "Try a few queries. The agent will use the graph if possible and call the builder tool if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in [\n",
    "    \"List Pikachu's evolution chain.\",\n",
    "    \"Is Pikachu weak against Ground?\",\n",
    "    \"Give Pikachu's type and one move it commonly uses.\",\n",
    "    \"What item is needed to evolve Pikachu?\"\n",
    "]:\n",
    "    out = answer_with_graph(q)\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A:\", out.answer)\n",
    "    print(\"Used builder tool:\", out.used_builder)\n",
    "    print(\"Evidence:\", out.evidence[:2])\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reliability: lightweight checks\n",
    "\n",
    "You can add more *guardrails*:\n",
    "- **Result validator** to clip/normalize fields or reject low‚Äëconfidence triples.\n",
    "- **Critic iterations** > 2 for tougher tasks.\n",
    "- **Schema hardening**: restrict entity strings to known lists, require certain edges per query type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: clip confidence to [0.0, 1.0] and drop very low-confidence edges before persisting\n",
    "def sanitize(result: BuildKGResult, min_conf: float = 0.4) -> BuildKGResult:\n",
    "    keep = []\n",
    "    for tri in result.triples:\n",
    "        tri.confidence = max(0.0, min(1.0, tri.confidence))\n",
    "        if tri.confidence >= min_conf:\n",
    "            keep.append(tri)\n",
    "    return BuildKGResult(entities=sorted(set(result.entities)), triples=keep)\n",
    "\n",
    "# Use it like:\n",
    "r = build_kg_for_query(\"Ensure one move and type for Pikachu\")\n",
    "r = sanitize(r, min_conf=0.5)\n",
    "add_build_result_to_graph(r)\n",
    "print(\"Sanitized & persisted\", len(r.triples), \"triples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Backend choices & performance notes\n",
    "\n",
    "- Graphiti supports **Neo4j, FalkorDB, K√πzu, Amazon Neptune** backends and uses **OpenSearch** for full‚Äëtext where relevant.  \n",
    "  See Graphiti README **Requirements** and quickstart.  \n",
    "- Try **FalkorDB** with Docker for a zero‚Äësetup local graph; or use **Neo4j Desktop**.\n",
    "\n",
    "> If using FalkorDB/Neo4j, replace the shim here with real Graphiti usage and its query utilities; method names like `add_triplet` and neighborhood/edge lookup map onto Graphiti‚Äôs graph API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. References & further reading\n",
    "\n",
    "- Graphiti overview & install (README) ‚Äî *requirements, structured output note, backends, MCP server*:  \n",
    "  - https://github.com/getzep/graphiti  \n",
    "  - https://help.getzep.com/graphiti/getting-started/overview  \n",
    "  - MCP server intro: https://help.getzep.com/graphiti/getting-started/mcp-server\n",
    "\n",
    "- PydanticAI ‚Äî *tools & structured outputs*:  \n",
    "  - Tools: https://ai.pydantic.dev/tools/  \n",
    "  - Output / structured results: https://ai.pydantic.dev/output/\n",
    "\n",
    "- Why KG for agents (temporal, dynamic):  \n",
    "  - Neo4j blog summary of Graphiti: https://neo4j.com/blog/developer/graphiti-knowledge-graph-memory/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What you learned üí°\n",
    "\n",
    "- Designing a **schema-first** KG eliminates a lot of mess.\n",
    "- A **builder‚Üícritic** loop catches schema violations & hallucinations early.\n",
    "- An **answering agent with a KG-builder tool** gives **on‚Äëdemand graphing** + **precise answers**.\n",
    "- This pattern scales to larger domains and document corpora (‚Üí **GraphRAG**). In the next tutorial, we‚Äôll compare **dynamic Graphiti** with **precomputed GraphRAG** and hybridize them."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tutorial 5 ‚Äî Dynamic KGs with Graphiti + PydanticAI (Pikachu)"
  },
  "kernelspec": {
   "display_name": "build-your-own-super-agents (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
