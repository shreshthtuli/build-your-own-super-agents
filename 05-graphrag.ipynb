{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Knowledge Graphs and GraphRAG\n",
    "\n",
    "So far in this course, we‚Äôve explored **traditional RAG (Retrieval-Augmented Generation)** ‚Äî a paradigm where large language models retrieve **unstructured text chunks** from vector databases (like FAISS or LanceDB) and synthesize answers on-the-fly.  \n",
    "\n",
    "While RAG works well for surface-level question answering, it **struggles with structure, reasoning, and relationships**. It treats text as isolated passages ‚Äî not as **entities** linked by meaning or causality.  That‚Äôs where **Knowledge Graphs** and **GraphRAG** step in.\n",
    "\n",
    "## üß† Why Knowledge Graphs?\n",
    "\n",
    "A **Knowledge Graph (KG)** represents knowledge as **nodes (entities)** and **edges (relationships)**, creating a structured and interpretable memory.  \n",
    "In contrast to flat vector retrieval, KGs allow an agent to:\n",
    "\n",
    "- **Reason symbolically** ‚Äî follow explicit paths like *‚ÄúPichu ‚Üí Pikachu ‚Üí Raichu‚Äù*.  \n",
    "- **Disambiguate entities** ‚Äî distinguish *Thunderbolt (move)* vs *Thunderbolt (item)*.  \n",
    "- **Fuse multi-source facts** ‚Äî merging structured and unstructured evidence.  \n",
    "- **Explain answers** ‚Äî show the exact graph edges used in reasoning.\n",
    "\n",
    "This yields an AI system that is not only more **precise** but also **auditable** and **less hallucinatory**.\n",
    "\n",
    "**GraphRAG** blends the strengths of retrieval and structured reasoning:\n",
    "1. **Retrieve** relevant context ‚Üí turn it into triples (`(subject, predicate, object)`).\n",
    "2. **Store / update** these triples in a **graph backend** (persistent memory).  \n",
    "3. **Reason on the graph** to answer complex or multi-hop queries.\n",
    "\n",
    "In essence, **GraphRAG = RAG + Knowledge Graph Reasoning**. Instead of searching documents, we query the graph ‚Äî traversing relationships explicitly.\n",
    "\n",
    "\n",
    "## üß© Enter Graphiti + FalkorDB\n",
    "\n",
    "We‚Äôll use the [**Graphiti**](https://github.com/getzep/graphiti) library ‚Äî a lightweight, production-grade framework for building **temporal knowledge graphs** that integrate directly with LLMs.  \n",
    "\n",
    "**FalkorDB** is a **high-performance graph database** built on Redis, which we use as the backend for Graphiti. It combines the **speed of in-memory databases** with **Cypher-style graph queries**, making it perfect for real-time AI agents that need to evolve their graph dynamically.\n",
    "\n",
    "Graphiti uses structured outputs from LLMs to **extract triples**, **store them as graph edges**, and **enable reasoning** through its built-in query APIs and MCP server. Together, Graphiti + FalkorDB create the ideal playground for **GraphRAG agents** ‚Äî ones that can remember, reason, and adapt.\n",
    "\n",
    "However, let's first start with what it takes to create graphical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97987497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from typing import List, Optional, Literal, Tuple, Dict\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()  # expects OPENROUTER_API_KEY in your environment\n",
    "\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "CHAT_MODEL = \"openrouter:google/gemini-2.5-flash\"\n",
    "EMBED_MODEL = \"openai/text-embedding-3-large\"\n",
    "\n",
    "openai = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "EPISODES = [\n",
    "    \"\"\"Ash meets a timid Pichu that later evolves into Pikachu using friendship.\n",
    "       Pikachu is an Electric-type and often uses Thunderbolt against Team Rocket.\"\"\",\n",
    "    \"\"\"During a gym battle, Pikachu faces a Ground-type opponent and struggles due to type disadvantage.\n",
    "       Raichu appears later as Pikachu's evolution with a Thunder Stone.\"\"\",\n",
    "    \"\"\"Pikachu practices Quick Attack in the forest. Trainers discuss that Electric resists Flying and Steel.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cf3e2",
   "metadata": {},
   "source": [
    "### üß© Define the Schema and Create a Triple-Extraction Agent\n",
    "\n",
    "Before we can build a knowledge graph, we need to define **what relationships are allowed**. We‚Äôll describe our Pok√©mon world using a small, fixed schema of predicates such as:\n",
    "\n",
    "- `HAS_TYPE` ‚Äî connects a Pok√©mon to its elemental type  \n",
    "- `EVOLVES_TO` ‚Äî shows evolution paths  \n",
    "- `NEEDS_ITEM` ‚Äî evolution dependency (e.g., Thunder Stone)  \n",
    "- `LEARNS_MOVE` ‚Äî captures learnable moves  \n",
    "- `WEAK_AGAINST`, `RESISTS` ‚Äî for type matchups  \n",
    "\n",
    "Using this schema, we‚Äôll create two **Pydantic models**:\n",
    "1. `Triple` ‚Äî represents one edge (`subject`, `predicate`, `object`)  \n",
    "2. `BuildKGResult` ‚Äî wraps the list of extracted entities and triples  \n",
    "\n",
    "Finally, we‚Äôll define a **PydanticAI Agent** called `builder` that takes raw episode text and returns structured triples according to our schema. This mimics how an information-extraction LLM in Graphiti works under the hood ‚Äî but here we do it manually for clarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a620fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "\n",
    "ValidPredicates = Literal[\n",
    "    \"HAS_TYPE\", \"EVOLVES_TO\", \"NEEDS_ITEM\", \"LEARNS_MOVE\", \"WEAK_AGAINST\", \"RESISTS\"\n",
    "]\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    subject: str\n",
    "    predicate: ValidPredicates\n",
    "    object: str\n",
    "    fact: Optional[str] = None\n",
    "    confidence: float = Field(0.9, ge=0.0, le=1.0)\n",
    "\n",
    "class BuildKGResult(BaseModel):\n",
    "    entities: List[str]\n",
    "    triples: List[Triple]\n",
    "\n",
    "builder = Agent[None, BuildKGResult](\n",
    "    model=CHAT_MODEL,\n",
    "    system_prompt=(\n",
    "        \"You are a precise IE system. Extract schema-conformant triples ONLY from the provided episode text.\\n\"\n",
    "        \"Schema:\\n\"\n",
    "        \"- Entities: Pokemon/Type/Move/Item are plain strings (e.g., 'Pikachu', 'Electric', 'Thunderbolt', 'Thunder Stone').\\n\"\n",
    "        \"- Relations: HAS_TYPE(Pokemon‚ÜíType), EVOLVES_TO(Pokemon‚ÜíPokemon), NEEDS_ITEM(Pokemon‚ÜíItem), \"\n",
    "        \"LEARNS_MOVE(Pokemon‚ÜíMove), WEAK_AGAINST(Pokemon‚ÜíType), RESISTS(Pokemon‚ÜíType)\\n\"\n",
    "        \"Return a JSON with 'entities' and 'triples'.\"\n",
    "    ),\n",
    "    output_type=BuildKGResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f842a",
   "metadata": {},
   "source": [
    "### üï∏Ô∏è Build a Minimal In-Memory Graph\n",
    "\n",
    "Now that we can extract structured triples from episode text, we need a simple data structure to **store them as a graph** ‚Äî with **nodes** and **edges**.\n",
    "\n",
    "Here we‚Äôll implement a lightweight `MiniGraph` class that:\n",
    "- Keeps track of **nodes** (unique entity names like *Pikachu*, *Electric*, *Thunderbolt*)  \n",
    "- Stores **edges** (`subject ‚Üí predicate ‚Üí object`) as `Edge` dataclasses  \n",
    "- Provides helper methods to generate text corpora of nodes and edges for embedding later\n",
    "\n",
    "We‚Äôll also use `logfire` to instrument PydanticAI for observability and apply `nest_asyncio` so that async agents can run smoothly inside notebooks.\n",
    "\n",
    "Finally, we‚Äôll loop through our Pok√©mon episode texts, extract triples using the `builder` agent, and populate the graph.  \n",
    "This gives us an interpretable **knowledge graph memory** ‚Äî before we move on to embedding and semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e414aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-eu.pydantic.dev/shreshthtuli/agenticai\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-eu.pydantic.dev/shreshthtuli/agenticai</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=504684;https://logfire-eu.pydantic.dev/shreshthtuli/agenticai\u001b\\\u001b[4;36mhttps://logfire-eu.pydantic.dev/shreshthtuli/agenticai\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:22:03.638 builder run\n",
      "17:22:03.644   chat google/gemini-2.5-flash\n",
      "17:22:05.713 builder run\n",
      "17:22:05.714   chat google/gemini-2.5-flash\n",
      "17:22:07.019 builder run\n",
      "17:22:07.028   chat google/gemini-2.5-flash\n",
      "Nodes: 10\n",
      "Edges: 9\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import logfire\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "logfire.configure()\n",
    "logfire.instrument_pydantic_ai()\n",
    "\n",
    "@dataclass\n",
    "class Edge:\n",
    "    subject: str\n",
    "    predicate: str\n",
    "    object: str\n",
    "    fact: str = \"\"\n",
    "    confidence: float = 1.0\n",
    "\n",
    "class MiniGraph:\n",
    "    def __init__(self):\n",
    "        self.nodes = set()\n",
    "        self.edges: List[Edge] = []\n",
    "        # embedding indexes\n",
    "        self.node_texts: List[str] = []    # e.g., node labels like \"Pikachu\"\n",
    "        self.node_vecs: List[List[float]] = []\n",
    "        self.edge_texts: List[str] = []    # e.g., \"(Pikachu)-[HAS_TYPE]->(Electric)\"\n",
    "        self.edge_vecs: List[List[float]] = []\n",
    "\n",
    "    def add_triple(self, t: Triple):\n",
    "        self.nodes.add(t.subject); self.nodes.add(t.object)\n",
    "        self.edges.append(Edge(t.subject, t.predicate, t.object, t.fact or \"\", t.confidence))\n",
    "\n",
    "    def node_corpus(self) -> List[str]:\n",
    "        return sorted(self.nodes)\n",
    "\n",
    "    def edge_corpus(self) -> List[str]:\n",
    "        return [f\"({e.subject})-[{e.predicate}]->({e.object}) :: {e.fact}\" for e in self.edges]\n",
    "\n",
    "GRAPH = MiniGraph()\n",
    "\n",
    "def add_episode_to_graph(text: str):\n",
    "    res = builder.run_sync(f\"Episode:\\n{text}\").output\n",
    "    for t in res.triples:\n",
    "        GRAPH.add_triple(t)\n",
    "    return res\n",
    "\n",
    "for ep in EPISODES:\n",
    "    add_episode_to_graph(ep)\n",
    "\n",
    "print(\"Nodes:\", len(GRAPH.nodes))\n",
    "print(\"Edges:\", len(GRAPH.edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0871e",
   "metadata": {},
   "source": [
    "Let's see what graph was generated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf2a3691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #af00ff; text-decoration-color: #af00ff\">üï∏Ô∏è Knowledge Graph Summary</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;5;129müï∏Ô∏è Knowledge Graph Summary\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Nodes</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">)</span>: Electric, Flying, Ground, Pichu, Pikachu, Quick Attack, Raichu, Steel, Thunder Stone, Thunderbolt\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mNodes\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m: Electric, Flying, Ground, Pichu, Pikachu, Quick Attack, Raichu, Steel, Thunder Stone, Thunderbolt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Edges</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mEdges\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Pichu) -[EVOLVES_TO]-> (Pikachu)  | fact: Pichu that later evolves into Pikachu using friendship  [conf=0.90]\n",
      "  (Pikachu) -[HAS_TYPE]-> (Electric)  | fact: Pikachu is an Electric-type  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Thunderbolt)  | fact: Pikachu is an Electric-type and often uses Thunderbolt against Team Rocket  [conf=0.90]\n",
      "  (Pikachu) -[WEAK_AGAINST]-> (Ground)  [conf=0.90]\n",
      "  (Pikachu) -[EVOLVES_TO]-> (Raichu)  [conf=0.90]\n",
      "  (Pikachu) -[NEEDS_ITEM]-> (Thunder Stone)  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Quick Attack)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Flying)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Steel)  [conf=0.90]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "def pretty_print_graph(graph: MiniGraph):\n",
    "    rprint(f\"[purple]\\nüï∏Ô∏è Knowledge Graph Summary[/]\")\n",
    "    rprint(f\"[green]Nodes[/] ({len(graph.nodes)}): {', '.join(sorted(graph.nodes))}\\n\")\n",
    "    rprint(f\"[red]Edges[/] ({len(graph.edges)}):\")\n",
    "    for e in graph.edges:\n",
    "        print(f\"  ({e.subject}) -[{e.predicate}]-> ({e.object})\"\n",
    "              + (f\"  | fact: {e.fact}\" if e.fact else \"\")\n",
    "              + (f\"  [conf={e.confidence:.2f}]\" if e.confidence != 1.0 else \"\"))\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "pretty_print_graph(GRAPH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f5033b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:31:24.225 builder run\n",
      "11:31:24.226   chat google/gemini-2.5-flash\n",
      "11:31:25.875 New edge added: ('Raichu', 'WEAK_AGAINST', 'Ground')\n",
      "Iteration 1: added 1 new edges. Total now 11.\n",
      "11:31:25.891 builder run\n",
      "11:31:25.891   chat google/gemini-2.5-flash\n",
      "11:31:27.201 New edge added: ('Raichu', 'RESISTS', 'Flying')\n",
      "11:31:27.201 New edge added: ('Raichu', 'RESISTS', 'Steel')\n",
      "Iteration 2: added 2 new edges. Total now 13.\n",
      "11:31:27.205 builder run\n",
      "11:31:27.209   chat google/gemini-2.5-flash\n",
      "11:31:30.294 New edge added: ('Pikachu', 'RESISTS', 'Flying')\n",
      "11:31:30.294 New edge added: ('Pikachu', 'RESISTS', 'Steel')\n",
      "11:31:30.294 New edge added: ('Pikachu', 'RESISTS', 'Electric')\n",
      "11:31:30.294 New edge added: ('Pikachu', 'WEAK_AGAINST', 'Ground')\n",
      "Iteration 3: added 3 new edges. Total now 16.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #af00ff; text-decoration-color: #af00ff\">üï∏Ô∏è Knowledge Graph Summary</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;5;129müï∏Ô∏è Knowledge Graph Summary\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Nodes</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">)</span>: Electric, Flying, Ground, Pichu, Pikachu, Quick Attack, Raichu, Steel, Thunder Stone, Thunderbolt\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mNodes\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m)\u001b[0m: Electric, Flying, Ground, Pichu, Pikachu, Quick Attack, Raichu, Steel, Thunder Stone, Thunderbolt\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Edges</span> <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">)</span>:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mEdges\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1m)\u001b[0m:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Pichu) -[EVOLVES_TO]-> (Pikachu)  | fact: Pichu that later evolves into Pikachu using friendship  [conf=0.90]\n",
      "  (Pikachu) -[HAS_TYPE]-> (Electric)  | fact: Pikachu is an Electric-type  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Thunderbolt)  | fact: often uses Thunderbolt  [conf=0.90]\n",
      "  (Pikachu) -[WEAK_AGAINST]-> (Ground)  [conf=0.90]\n",
      "  (Raichu) -[HAS_TYPE]-> (Electric)  [conf=0.90]\n",
      "  (Pikachu) -[EVOLVES_TO]-> (Raichu)  [conf=0.90]\n",
      "  (Pikachu) -[NEEDS_ITEM]-> (Thunder Stone)  [conf=0.90]\n",
      "  (Pikachu) -[LEARNS_MOVE]-> (Quick Attack)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Flying)  [conf=0.90]\n",
      "  (Electric) -[RESISTS]-> (Steel)  [conf=0.90]\n",
      "  (Raichu) -[WEAK_AGAINST]-> (Ground)  | fact: Because Pikachu is Electric-type and weak to Ground, and Raichu is Electric-type, it is inferrable that Raichu is also weak to Ground.  [conf=0.90]\n",
      "  (Raichu) -[RESISTS]-> (Flying)  | fact: Because Pikachu is Electric-type and resists Flying, and Raichu is Electric-type, it is inferrable that Raichu also resists Flying.  [conf=0.90]\n",
      "  (Raichu) -[RESISTS]-> (Steel)  | fact: Because Pikachu is Electric-type and resists Steel, and Raichu is Electric-type, it is inferrable that Raichu also resists Steel.  [conf=0.90]\n",
      "  (Pikachu) -[RESISTS]-> (Flying)  | fact: Because Pikachu is Electric-type and resists Flying.  [conf=0.90]\n",
      "  (Pikachu) -[RESISTS]-> (Steel)  | fact: Because Pikachu is Electric-type and resists Steel.  [conf=0.90]\n",
      "  (Pikachu) -[RESISTS]-> (Electric)  | fact: Because Pikachu is Electric-type and resists Electric.  [conf=0.90]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy \n",
    "\n",
    "def reflect_and_expand(graph: MiniGraph, max_iters: int = 3):\n",
    "    prev_edge_count = -1\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < max_iters:\n",
    "        iteration += 1\n",
    "        current_count = len(graph.edges)\n",
    "        if current_count == prev_edge_count:\n",
    "            print(f\"No new edges found after iteration {iteration-1}. Stopping reflection.\")\n",
    "            break\n",
    "\n",
    "        prev_edge_count = current_count\n",
    "        graph_state = json.dumps([e.__dict__ for e in graph.edges], indent=2)\n",
    "\n",
    "        # Ask the same builder agent if new relationships can be added\n",
    "        prompt = (\n",
    "            f\"Here is the current knowledge graph:\\n{graph_state}\\n\\n\"\n",
    "            \"Reflect on it and see if any *implicit* or *missing* relationships \"\n",
    "            \"can be derived from this graph. Add only valid new triples, if any. \"\n",
    "            \"Return empty if nothing new can be inferred.\"\n",
    "        )\n",
    "\n",
    "        reflection = builder.run_sync(prompt).output\n",
    "\n",
    "        # Add new edges (if any)\n",
    "        added = 0\n",
    "        for t in reflection.triples:\n",
    "            logfire.info(f\"New edge added: {(t.subject, t.predicate, t.object)}\")\n",
    "            key = (t.subject, t.predicate, t.object)\n",
    "            existing = {(e.subject, e.predicate, e.object) for e in graph.edges}\n",
    "            if key not in existing:\n",
    "                graph.add_triple(t)\n",
    "                added += 1\n",
    "\n",
    "        print(f\"Iteration {iteration}: added {added} new edges. Total now {len(graph.edges)}.\")\n",
    "\n",
    "    return graph\n",
    "\n",
    "NEWGRAPH = reflect_and_expand(deepcopy(GRAPH))\n",
    "pretty_print_graph(NEWGRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ee95e",
   "metadata": {},
   "source": [
    "In this example, our **builder agent** initially extracted direct facts from the Pok√©mon episodes ‚Äî things like *‚ÄúPikachu evolves to Raichu‚Äù* or *‚ÄúPikachu has type Electric.‚Äù*  \n",
    "\n",
    "When we introduced the **reflection loop**, the agent began to **review its own graph output** and infer **missing or implicit relations**. For instance, it noticed that Pikachu also **resists Flying and Steel** ‚Äî facts implied by its Electric typing but not explicitly mentioned in the text.\n",
    "\n",
    "This reflective step acts as a lightweight **self-consistency check**:\n",
    "- It helps the model **fill small gaps** in knowledge by reasoning over the structure it already built.  \n",
    "- It can correct omissions or low-confidence facts without requiring another dataset.  \n",
    "- It converges automatically ‚Äî once the graph stabilizes (no new edges are added), the loop stops.\n",
    "\n",
    "In a larger system, this is the foundation of **agentic knowledge refinement** ‚Äî the same principle used by **Graphiti** and other **GraphRAG** frameworks to keep the knowledge graph both **complete** and **consistent** over time.\n",
    "\n",
    "### üéØ Embedding and Semantic Search\n",
    "\n",
    "Now that our mini knowledge graph is built and refined, the next step is to make it **searchable**. We‚Äôll embed both **nodes** (entity names) and **edges** (relationships) into vector space using the **OpenRouter embedding API** (`text-embedding-3-large` by OpenAI, accessed via OpenRouter).\n",
    "\n",
    "This lets us perform **semantic search** over the graph ‚Äî so instead of keyword lookups, we can find conceptually related entities and relationships.\n",
    "\n",
    "In this section:\n",
    "1. We define helper functions to **embed** text and **compute cosine similarity**.  \n",
    "2. Build vector indexes for all nodes and edges.  \n",
    "3. Implement simple **search functions** that return the top-K most semantically similar nodes or edges for any query.\n",
    "\n",
    "This is conceptually similar to what happens in **traditional RAG**, except here we are embedding **graph elements** instead of text chunks ‚Äî a key building block for **GraphRAG** reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efde9c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top nodes for 'Pikachu evolution item':\n",
      "[('Pikachu', 0.6038109820985103),\n",
      " ('Pichu', 0.5137344454239156),\n",
      " ('Raichu', 0.49602330682813606),\n",
      " ('Thunder Stone', 0.4325935945057776),\n",
      " ('Quick Attack', 0.34751407732015965)]\n",
      "Top edges for 'type disadvantage against Ground':\n",
      "[('(Pikachu)-[WEAK_AGAINST]->(Ground) :: ', 0.6187038417597363),\n",
      " ('(Electric)-[RESISTS]->(Flying) :: ', 0.4096086571588773),\n",
      " ('(Electric)-[RESISTS]->(Steel) :: ', 0.38052656641427385),\n",
      " ('(Pikachu)-[LEARNS_MOVE]->(Thunderbolt) :: often uses Thunderbolt',\n",
      "  0.34112547965992024),\n",
      " ('(Pikachu)-[HAS_TYPE]->(Electric) :: Pikachu is an Electric-type',\n",
      "  0.31840167619153525)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def embed_texts(texts: List[str]) -> List[List[float]]:\n",
    "    if not texts:\n",
    "        return []\n",
    "    resp = openai.embeddings.create(model=EMBED_MODEL, input=texts)\n",
    "    return [d.embedding for d in resp.data]\n",
    "\n",
    "def normalize(v: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.dot(normalize(a), normalize(b)))\n",
    "\n",
    "def build_vector_indexes():\n",
    "    GRAPH.node_texts = GRAPH.node_corpus()\n",
    "    GRAPH.node_vecs = embed_texts(GRAPH.node_texts)\n",
    "    GRAPH.edge_texts = GRAPH.edge_corpus()\n",
    "    GRAPH.edge_vecs = embed_texts(GRAPH.edge_texts)\n",
    "\n",
    "def search_nodes(query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
    "    if not GRAPH.node_texts:\n",
    "        return []\n",
    "    qv = embed_texts([query])[0]\n",
    "    sims = [cosine_sim(np.array(qv), np.array(v)) for v in GRAPH.node_vecs]\n",
    "    ranked = sorted(zip(GRAPH.node_texts, sims), key=lambda x: x[1], reverse=True)\n",
    "    return ranked[:k]\n",
    "\n",
    "def search_edges(query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
    "    if not GRAPH.edge_texts:\n",
    "        return []\n",
    "    qv = embed_texts([query])[0]\n",
    "    sims = [cosine_sim(np.array(qv), np.array(v)) for v in GRAPH.edge_vecs]\n",
    "    ranked = sorted(zip(GRAPH.edge_texts, sims), key=lambda x: x[1], reverse=True)\n",
    "    return ranked[:k]\n",
    "\n",
    "build_vector_indexes()\n",
    "\n",
    "print(\"Top nodes for 'Pikachu evolution item':\")\n",
    "pprint(search_nodes(\"Pikachu evolution item\"))\n",
    "\n",
    "print(\"Top edges for 'type disadvantage against Ground':\")\n",
    "pprint(search_edges(\"type disadvantage against Ground\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15965fa2",
   "metadata": {},
   "source": [
    "### üß≠ What is an Ontology (and why it matters for Graph/GraphRAG)?\n",
    "\n",
    "An **ontology** is a formal, shared specification of the **concepts (classes)** in a domain, their **attributes (properties)**, and the **relationships** among them.  \n",
    "In graph terms, it defines:\n",
    "- **Entity types** (e.g., `Pokemon`, `Type`, `Move`, `Item`)\n",
    "- **Attributes** on entities (e.g., `Pokemon.stage`, `Move.power`)\n",
    "- **Relation types** (e.g., `HAS_TYPE`, `EVOLVES_TO`, `LEARNS_MOVE`)\n",
    "- **Domain/Range constraints** (what can connect to what) and sometimes **cardinalities** (e.g., `Pokemon HAS_TYPE Type`)\n",
    "\n",
    "A good ontology:\n",
    "- **Reduces hallucinations** by constraining what can be asserted\n",
    "- **Improves explainability** because answers refer to explicit entities/relations\n",
    "- **Enables reusable reasoning** across tasks (querying, validation, analytics)\n",
    "\n",
    "See more on [FalkorDB's blog](https://www.falkordb.com/blog/understanding-ontologies-knowledge-graph-schemas/).\n",
    "\n",
    "**Pragmatic recipe to design one**\n",
    "1. List **core entities** and the questions you must answer.  \n",
    "2. Define **relations** that connect those entities (domain/range).  \n",
    "3. Add **attributes** needed for reasoning (and keep the rest out).  \n",
    "4. Start small; **iterate** with real data; add constraints as you go.  \n",
    "\n",
    "Allthough ontologies can be created by LLMs like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0a761ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:34:01.671 ontology_suggester run\n",
      "11:34:01.674   chat google/gemini-2.5-flash\n",
      "=== Ontology Proposal ===\n",
      "{\n",
      "  \"classes\": [\n",
      "    {\n",
      "      \"name\": \"Pokemon\",\n",
      "      \"description\": \"A creature with unique abilities and types.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"The name of the Pokemon\",\n",
      "          \"required\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"stage\",\n",
      "          \"dtype\": \"int\",\n",
      "          \"description\": \"Evolution stage of the Pokemon\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Type\",\n",
      "      \"description\": \"A category that defines a Pokemon's strengths and weaknesses.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"The name of the type (e.g., Electric, Ground)\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Move\",\n",
      "      \"description\": \"An action a Pokemon can perform in battle.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"The name of the move (e.g., Thunderbolt, Quick Attack)\",\n",
      "          \"required\": false\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"power\",\n",
      "          \"dtype\": \"int\",\n",
      "          \"description\": \"The base power of the move\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Item\",\n",
      "      \"description\": \"An object that can be used by or on a Pokemon to achieve a specific effect.\",\n",
      "      \"attributes\": [\n",
      "        {\n",
      "          \"name\": \"name\",\n",
      "          \"dtype\": \"string\",\n",
      "          \"description\": \"The name of the item (e.g., Thunder Stone)\",\n",
      "          \"required\": false\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"relations\": [\n",
      "    {\n",
      "      \"name\": \"HAS_TYPE\",\n",
      "      \"description\": \"Indicates the type of a Pokemon.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Type\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"EVOLVES_TO\",\n",
      "      \"description\": \"Indicates what Pokemon another Pokemon evolves into.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Pokemon\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"NEEDS_ITEM\",\n",
      "      \"description\": \"Indicates an item needed for a Pokemon's evolution.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Item\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"LEARNS_MOVE\",\n",
      "      \"description\": \"Indicates a move a Pokemon can learn.\",\n",
      "      \"domain\": \"Pokemon\",\n",
      "      \"range\": \"Move\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"WEAK_AGAINST\",\n",
      "      \"description\": \"Indicates a type that another type is weak against.\",\n",
      "      \"domain\": \"Type\",\n",
      "      \"range\": \"Type\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"RESISTS\",\n",
      "      \"description\": \"Indicates a type that another type resists.\",\n",
      "      \"domain\": \"Type\",\n",
      "      \"range\": \"Type\"\n",
      "    }\n",
      "  ],\n",
      "  \"notes\": \"This ontology focuses on Pokemon, their types, moves, and evolution mechanics relevant to the provided examples. It supports queries about evolution, type advantages/disadvantages, and moves.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class OntologyAttribute(BaseModel):\n",
    "    name: str\n",
    "    dtype: Literal[\"string\",\"int\",\"float\",\"bool\",\"datetime\",\"enum\",\"id\"] = \"string\"\n",
    "    description: Optional[str] = None\n",
    "    required: bool = False\n",
    "\n",
    "class OntologyClass(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    attributes: List[OntologyAttribute] = Field(default_factory=list)\n",
    "\n",
    "class OntologyRelation(BaseModel):\n",
    "    name: str\n",
    "    description: Optional[str] = None\n",
    "    domain: str  # class name\n",
    "    range: str   # class name\n",
    "\n",
    "class OntologyProposal(BaseModel):\n",
    "    classes: List[OntologyClass]\n",
    "    relations: List[OntologyRelation]\n",
    "    notes: Optional[str] = None\n",
    "\n",
    "ontology_suggester = Agent(\n",
    "    model=CHAT_MODEL,\n",
    "    system_prompt=(\n",
    "        \"You are an ontology engineer. Given example domain text, propose a SMALL, \"\n",
    "        \"pragmatic ontology capturing key classes, attributes, and relations. \"\n",
    "        \"Keep it minimal but sufficient for QA and reasoning. Prefer concise names. \"\n",
    "        \"Return structured JSON matching OntologyProposal.\"\n",
    "    ),\n",
    "    output_type=OntologyProposal,\n",
    ")\n",
    "\n",
    "def suggest_ontology_from_examples(texts: List[str]) -> OntologyProposal:\n",
    "    corpus = \"\\n\\n---\\n\\n\".join(texts)\n",
    "    prompt = (\n",
    "        \"Domain examples:\\n\"\n",
    "        f\"{corpus}\\n\\n\"\n",
    "        \"Requirements:\\n\"\n",
    "        \"- Classes should include Pokemon, Type, Move, and Item if present.\\n\"\n",
    "        \"- Add minimal attributes that are useful for Q&A (e.g., power for moves, stage for pokemon).\\n\"\n",
    "        \"- Add relations like HAS_TYPE, EVOLVES_TO, NEEDS_ITEM, LEARNS_MOVE, WEAK_AGAINST, RESISTS.\\n\"\n",
    "        \"- You may add brief descriptions.\\n\"\n",
    "        \"- Keep it compact. Avoid unnecessary ontology.\"\n",
    "    )\n",
    "    return ontology_suggester.run_sync(prompt).output\n",
    "\n",
    "proposal = suggest_ontology_from_examples(EPISODES)\n",
    "\n",
    "print(\"=== Ontology Proposal ===\")\n",
    "print(json.dumps(proposal.model_dump(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561ac2bc",
   "metadata": {},
   "source": [
    "## üß© Graphiti abstraction\n",
    "\n",
    "All these embedding and search operations are automatically handled inside **Graphiti**.  \n",
    "It provides:\n",
    "- Configurable **embedders** and **cross-encoders** for reranking  \n",
    "- Persistent **vector indexes** linked to graph nodes  \n",
    "- Integration with real graph backends (e.g., **FalkorDB**, **Neo4j**)  \n",
    "- APIs to search, rank, and traverse the graph directly  \n",
    "\n",
    "So while we‚Äôre writing these utilities manually here to understand the mechanics, in the next section we‚Äôll switch to **Graphiti**, which abstracts away all this boilerplate and provides a much more powerful, production-ready interface.\n",
    "\n",
    "Let's first create the FalkorDB as a backend for Graphiti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552be5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è¨ Pulling falkordb/falkordb:latest (if needed)...\n",
      "üöÄ Starting FalkorDB with persistence at C:\\Users\\SHRESHTH\\Desktop\\build-your-own-super-agents\\db\\falkordb_data\n",
      "   - Container: 6ee093a3de57\n",
      "   - UI: http://localhost:3000  |  Redis: localhost:6379\n"
     ]
    }
   ],
   "source": [
    "from graphiti_core import Graphiti\n",
    "from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient\n",
    "from graphiti_core.llm_client.openai_client import OpenAIClient\n",
    "from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig\n",
    "from graphiti_core.driver.falkordb_driver import FalkorDriver\n",
    "from graphiti_core.llm_client.config import LLMConfig\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from src.falkordb_setup import run_falkordb, save_db\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "falkordb_container = run_falkordb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f08d61",
   "metadata": {},
   "source": [
    "In **Graphiti**, these three components play the same roles as in a traditional RAG pipeline ‚Äî but for **graph-based reasoning** instead of plain text retrieval.\n",
    "\n",
    "1. **LLM Client (`OpenAIGenericClient`)**  \n",
    "   - This wraps the language model endpoint (in our case, **Gemini 2.5 Flash** via OpenRouter).  \n",
    "   - It‚Äôs used for all generative tasks inside Graphiti ‚Äî such as extracting triples, summarizing nodes, or generating context-aware graph queries.\n",
    "\n",
    "2. **Embedder (`OpenAIEmbedder`)**  \n",
    "   - Similar to the vector embedder in RAG, it converts text, entity names, or relationships into dense embeddings for **semantic similarity search** within the graph.  \n",
    "   - We use `text-embedding-3-large` from OpenAI to create these embeddings, allowing Graphiti to find related nodes or documents efficiently.\n",
    "\n",
    "3. **Cross-Encoder / Re-ranker (`OpenAIRerankerClient`)**  \n",
    "   - After retrieval, multiple candidate nodes or subgraphs may be found.  \n",
    "   - The reranker uses a small LLM to **score and reorder** these candidates based on their semantic relevance to the query, improving precision.  \n",
    "   - This is analogous to the reranking step in advanced RAG setups.\n",
    "\n",
    "Together, these components form the **reasoning and retrieval core** of Graphiti. *The embedder finds relevant graph pieces, the reranker prioritizes them, and the LLM client performs reasoning over the final context.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2e06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphiti_core.utils.maintenance.graph_data_operations import clear_data\n",
    "from datetime import datetime\n",
    "\n",
    "llm_config = LLMConfig(api_key=os.getenv(\"OPENROUTER_API_KEY\"), \n",
    "                       base_url=\"https://openrouter.ai/api/v1\", \n",
    "                       model=\"x-ai/grok-4-fast\",\n",
    "                       small_model=\"x-ai/grok-4-fast\")\n",
    "client = OpenAIClient(config=llm_config, reasoning='medium')\n",
    "\n",
    "embedder_config = OpenAIEmbedderConfig(api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "                                       base_url=\"https://openrouter.ai/api/v1\",\n",
    "                                       embedding_model=\"openai/text-embedding-3-large\")\n",
    "embedder = OpenAIEmbedder(embedder_config)\n",
    "\n",
    "reranker = OpenAIRerankerClient(llm_config)\n",
    "\n",
    "driver = FalkorDriver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c2e7cb",
   "metadata": {},
   "source": [
    "### üß± Defining Entity and Relationship Schemas for Graphiti\n",
    "\n",
    "Now that we understand how knowledge graphs can be built manually, let‚Äôs formalize our Pok√©mon world using **Graphiti‚Äôs structured schema definitions**.\n",
    "\n",
    "We define:\n",
    "- **Entity types** like `Pokemon`, `Type`, `Move`, and `Item` ‚Äî each with optional attributes (e.g., `stage`, `power`, `effect`).\n",
    "- **Edge types** like `HAS_TYPE`, `EVOLVES_TO`, `LEARNS_MOVE`, etc. ‚Äî describing allowed relationships between entities.\n",
    "\n",
    "The `edge_type_map` explicitly specifies **which relationships are permitted** between each entity pair (e.g., `Pokemon ‚Üí Type` can have `HAS_TYPE`, `WEAK_AGAINST`, or `RESISTS`).\n",
    "\n",
    "Finally, we initialize a **Graphiti instance** connected to the FalkorDB driver,  \n",
    "and load our Pok√©mon episode data into it using `add_episode()`.  \n",
    "This automatically handles:\n",
    "- LLM-based triple extraction  \n",
    "- Schema validation  \n",
    "- Embedding and storage in the graph backend  \n",
    "\n",
    "Essentially, this is the **Graphiti abstraction** over everything we built manually earlier ‚Äî offering schema-aware KG construction, persistence, and reasoning in one unified interface.\n",
    "\n",
    "For our use-case, we define a fixed ontology as follows. We will use [Graphiti's custom entities and edges](https://help.getzep.com/graphiti/core-concepts/custom-entity-and-edge-types) to encode this ontology for our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "062df90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphiti_core.nodes import EpisodeType\n",
    "from pathlib import Path\n",
    "import os \n",
    "\n",
    "# Entities\n",
    "class Pokemon(BaseModel):\n",
    "    \"\"\"A Pokemon species or evolutionary form.\"\"\"\n",
    "    stage: Optional[int] = Field(None, description=\"Evolution stage number (e.g., Pichu is 1, Pikachu is 2, Raichu is 3)\")\n",
    "\n",
    "class Type(BaseModel):\n",
    "    \"\"\"Elemental typing such as Electric, Ground, Flying.\"\"\"\n",
    "    category: Optional[str] = Field(None, description=\"Damage class or grouping if applicable\")\n",
    "\n",
    "class Move(BaseModel):\n",
    "    \"\"\"A move a Pokemon can learn or use.\"\"\"\n",
    "    power: Optional[int] = Field(None, description=\"Base power if applicable\")\n",
    "    move_type: Optional[str] = Field(None, description=\"Type of the move, e.g., Electric\")\n",
    "\n",
    "class Item(BaseModel):\n",
    "    \"\"\"An evolution or battle item.\"\"\"\n",
    "    effect: Optional[str] = Field(None, description=\"Short description of the item effect\")\n",
    "\n",
    "# Edges\n",
    "class HasType(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Type\"\"\"\n",
    "    pass\n",
    "\n",
    "class EvolvesTo(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Pokemon\"\"\"\n",
    "    method: Optional[str] = Field(None, description=\"Evolution method (friendship, level, etc.)\")\n",
    "\n",
    "class NeedsItem(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Item\"\"\"\n",
    "    reason: Optional[str] = Field(None, description=\"Why the item is required (e.g., evolve)\")\n",
    "\n",
    "class LearnsMove(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Move\"\"\"\n",
    "    learn_method: Optional[str] = Field(None, description=\"TM/TR/Level-up/etc.\")\n",
    "    level: Optional[int] = Field(None, description=\"Level when learned, if applicable\")\n",
    "\n",
    "class WeakAgainst(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Type\"\"\"\n",
    "    note: Optional[str] = Field(None, description=\"Context note\")\n",
    "\n",
    "class Resists(BaseModel):\n",
    "    \"\"\"Pokemon ‚Üí Type\"\"\"\n",
    "    note: Optional[str] = Field(None, description=\"Context note\")\n",
    "\n",
    "# Entity and edge registries\n",
    "entity_types: Dict[str, type] = {\n",
    "    \"Pokemon\": Pokemon,\n",
    "    \"Type\": Type,\n",
    "    \"Move\": Move,\n",
    "    \"Item\": Item,\n",
    "}\n",
    "\n",
    "edge_types: Dict[str, type] = {\n",
    "    \"HAS_TYPE\": HasType,\n",
    "    \"EVOLVES_TO\": EvolvesTo,\n",
    "    \"NEEDS_ITEM\": NeedsItem,\n",
    "    \"LEARNS_MOVE\": LearnsMove,\n",
    "    \"WEAK_AGAINST\": WeakAgainst,\n",
    "    \"RESISTS\": Resists,\n",
    "}\n",
    "\n",
    "# Which edge types are allowed between which entity pairs\n",
    "edge_type_map: Dict[Tuple[str, str], List[str]] = {\n",
    "    (\"Pokemon\", \"Type\"): [\"HAS_TYPE\", \"WEAK_AGAINST\", \"RESISTS\"],\n",
    "    (\"Pokemon\", \"Pokemon\"): [\"EVOLVES_TO\"],\n",
    "    (\"Pokemon\", \"Item\"): [\"NEEDS_ITEM\"],\n",
    "    (\"Pokemon\", \"Move\"): [\"LEARNS_MOVE\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caddef0",
   "metadata": {},
   "source": [
    "### üé¨ Splitting Text into Self-Contained Episodes\n",
    "\n",
    "Before adding data into the knowledge graph, we need to break long Pok√©mon narratives  \n",
    "(such as full transcripts or story summaries) into smaller, **coherent segments** called *episodes*.\n",
    "\n",
    "Each `Episode` should represent a complete scene or event ‚Äî containing enough context  \n",
    "for the LLM to extract entities and relationships without depending on other segments.\n",
    "\n",
    "In this step:\n",
    "- We define a **Pydantic model** `Episode` with fields for `name`, `episode_body`, and `source_description`.  \n",
    "  A `field_validator` ensures titles are short and clean.\n",
    "- We create a `EpisodesResult` wrapper to hold multiple episodes.\n",
    "- We then use a **PydanticAI Agent**, `episode_generator`, which takes a long Pok√©mon text and  \n",
    "  splits it into coherent `Episode` objects.\n",
    "\n",
    "This segmentation step ensures the graph builder later works on **focused, semantically consistent chunks**,  \n",
    "just like scene segmentation in a movie ‚Äî enabling better entity extraction and cleaner graph structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f060bc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:24:10.483 episode_generator run\n",
      "17:24:10.483   chat google/gemini-2.5-flash\n",
      "17:24:12.554   chat google/gemini-2.5-flash\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">EpisodesResult</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">episodes</span>=<span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Episode</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Ash Meets Timid Pichu and Evolution'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">episode_body</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Ash encounters a timid Pichu, a small, yellow mouse-like Pok√©mon known for its electric </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cheeks. Through their interactions and developing bond, the Pichu overcomes its shyness and strong friendship </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">blossoms between them. This deep friendship ultimately triggers Pichu's evolution into a Pikachu, a more powerful </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Electric-type Pok√©mon with enhanced abilities.\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">source_description</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'episode'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Episode</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Pikachu's Electric Attacks Against Team Rocket\"</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">episode_body</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Pikachu, an Electric-type Pok√©mon, is a loyal companion to Ash and often finds itself in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">battles, particularly against the villainous Team Rocket. During these confrontations, Pikachu frequently unleashes</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">its signature move, Thunderbolt, a powerful electrical attack that incapacitates opponents and sends Team Rocket </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">blasting off again.'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">source_description</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'episode'</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mEpisodesResult\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mepisodes\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1;35mEpisode\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m'Ash Meets Timid Pichu and Evolution'\u001b[0m,\n",
       "            \u001b[33mepisode_body\u001b[0m=\u001b[32m\"Ash\u001b[0m\u001b[32m encounters a timid Pichu, a small, yellow mouse-like Pok√©mon known for its electric \u001b[0m\n",
       "\u001b[32mcheeks. Through their interactions and developing bond, the Pichu overcomes its shyness and strong friendship \u001b[0m\n",
       "\u001b[32mblossoms between them. This deep friendship ultimately triggers Pichu's evolution into a Pikachu, a more powerful \u001b[0m\n",
       "\u001b[32mElectric-type Pok√©mon with enhanced abilities.\"\u001b[0m,\n",
       "            \u001b[33msource_description\u001b[0m=\u001b[32m'episode'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[1;35mEpisode\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mname\u001b[0m=\u001b[32m\"Pikachu\u001b[0m\u001b[32m's Electric Attacks Against Team Rocket\"\u001b[0m,\n",
       "            \u001b[33mepisode_body\u001b[0m=\u001b[32m'Pikachu, an Electric-type Pok√©mon, is a loyal companion to Ash and often finds itself in \u001b[0m\n",
       "\u001b[32mbattles, particularly against the villainous Team Rocket. During these confrontations, Pikachu frequently unleashes\u001b[0m\n",
       "\u001b[32mits signature move, Thunderbolt, a powerful electrical attack that incapacitates opponents and sends Team Rocket \u001b[0m\n",
       "\u001b[32mblasting off again.'\u001b[0m,\n",
       "            \u001b[33msource_description\u001b[0m=\u001b[32m'episode'\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class Episode(BaseModel):\n",
    "    \"\"\"A coherent segment suitable for graph extraction.\"\"\"\n",
    "    name: str = Field(..., description=\"Short, unique episode title (e.g., 'Gym Battle in Pewter').\")\n",
    "    episode_body: str = Field(..., min_length=120, description=\"Self-contained text of the episode.\")\n",
    "    source_description: Optional[str] = Field(\"episode\", description=\"Provenance label (default: 'episode').\")\n",
    "\n",
    "    @field_validator(\"name\")\n",
    "    @classmethod\n",
    "    def strip_name(cls, v: str) -> str:\n",
    "        v = v.strip()\n",
    "        if len(v) > 120:\n",
    "            v = v[:117] + \"...\"\n",
    "        return v\n",
    "\n",
    "class EpisodesResult(BaseModel):\n",
    "    episodes: List[Episode]\n",
    "\n",
    "episode_generator = Agent(\n",
    "    model=CHAT_MODEL,\n",
    "    system_prompt=(\n",
    "        f\"\"\"\n",
    "        You are an expert segmenter. Split a long Pok√©mon-related context into coherent EPISODES.\n",
    "\n",
    "        Rules:\n",
    "        - Prioritize coherence over exact length.\n",
    "        - Each episode must be self-contained: enough detail so downstream IE can extract entities/relations without cross-episode references.\n",
    "        - Prefer semantic boundaries: scene changes, locations, battles, new characters/pokemon, or topic shifts.\n",
    "        - Titles should be short, unique, and descriptive.\n",
    "        - Respect chronology if provided; otherwise, group by topical coherence.\n",
    "        - Keep `source_description=\"episode\"` unless the input explicitly suggests otherwise (e.g., 'movie recap', 'blog post', etc.).\n",
    "        - NEVER fabricate content beyond the given text. If info is uncertain, omit it.\n",
    "\n",
    "        Output strictly as EpisodesResult JSON.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    output_type=EpisodesResult\n",
    ")\n",
    "\n",
    "response = episode_generator.run_sync(EPISODES[0])\n",
    "rprint(response.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2798c4c0",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Loading and Processing Pok√©mon Episodes into Graphiti\n",
    "\n",
    "Now that we‚Äôve defined our **episode segmentation agent** and **graph schema**,  \n",
    "we can put everything together to build a **complete knowledge graph** using **Graphiti**.\n",
    "\n",
    "In this step:\n",
    "1. **Initialize Graphiti** with:\n",
    "   - `graph_driver` ‚Üí our FalkorDB backend  \n",
    "   - `llm_client`, `embedder`, and `cross_encoder` ‚Üí for triple extraction, embedding, and reranking  \n",
    "   - `store_raw_episode_content=False` ‚Üí skips saving large text blobs to keep storage light\n",
    "\n",
    "2. **Prepare the environment**:\n",
    "   - `clear_data()` wipes any existing graph data.  \n",
    "   - `build_indices_and_constraints()` sets up indexes and schema-level constraints in the database.\n",
    "\n",
    "3. **Process local Pok√©mon markdown files**:\n",
    "   - Each file in `data/pokemon_md/` contains a text segment describing Pok√©mon interactions or battles.  \n",
    "   - We pass each file through the `episode_generator`, which splits it into coherent episodes.  \n",
    "   - Then each `Episode` is passed to `graphiti.add_episode()`, which:\n",
    "     - Extracts entities and relationships,  \n",
    "     - Embeds and links them,  \n",
    "     - Inserts them into the graph database with timestamps and group metadata.\n",
    "\n",
    "üîÅ This creates a **structured, queryable knowledge graph** from unstructured Pok√©mon text ‚Äî and demonstrates how Graphiti unifies the full workflow (segmentation ‚Üí extraction ‚Üí embedding ‚Üí persistence) that we previously built manually in separate steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32262350",
   "metadata": {},
   "outputs": [],
   "source": [
    "await graphiti.search('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHRESHTH\\AppData\\Local\\Temp\\ipykernel_14148\\4080363493.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for episode in tqdm(episodes[:2], \"Processing Files\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128b3c8fac2c4fe18f87627310d8fcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:24:19.568 episode_generator run\n",
      "17:24:19.571   chat google/gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHRESHTH\\AppData\\Local\\Temp\\ipykernel_14148\\4080363493.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for gep in tqdm(response.output.episodes[:1], desc=\"Processing episodes\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b622e58977ae4ad7be38dcedf9d7197e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing episodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:25:45.096 episode_generator run\n",
      "17:25:45.099   chat google/gemini-2.5-flash\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044191bd90424c0b86bda571e2c4f15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing episodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "graphiti = Graphiti(graph_driver=driver, llm_client=client, embedder=embedder, cross_encoder=reranker, store_raw_episode_content=False)\n",
    "\n",
    "await clear_data(graphiti.driver)\n",
    "await graphiti.build_indices_and_constraints(delete_existing=True)\n",
    "\n",
    "DB_FILES = \"data/pokemon_md/\"\n",
    "\n",
    "episodes = []\n",
    "for filename in os.listdir(DB_FILES):\n",
    "    episodes.append(Path(DB_FILES + filename).read_text(encoding='utf-8'))\n",
    "\n",
    "for episode in tqdm(episodes[:2], \"Processing Files\"):\n",
    "    response = episode_generator.run_sync(episode)\n",
    "    for gep in tqdm(response.output.episodes[:1], desc=\"Processing episodes\"):\n",
    "        await graphiti.add_episode(name=gep.name, \n",
    "                                episode_body=gep.episode_body, \n",
    "                                source_description=gep.source_description, \n",
    "                                source=EpisodeType.text, \n",
    "                                reference_time=datetime.now(),\n",
    "                                group_id=\"pokemon_data_tmp\", \n",
    "                                entity_types=entity_types, \n",
    "                                edge_types=edge_types, \n",
    "                                edge_type_map=edge_type_map)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f201b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved dump.rdb in db/falkordb_data/dump.rdb\n"
     ]
    }
   ],
   "source": [
    "save_db(falkordb_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad395f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Exported 3 nodes with label 'Entity' to db/falkordb_data/nodes_Entity.csv\n",
      "‚úÖ Exported 2 nodes with label 'Pokemon' to db/falkordb_data/nodes_Pokemon.csv\n",
      "‚úÖ Exported 1 nodes with label 'Episodic' to db/falkordb_data/nodes_Episodic.csv\n",
      "‚úÖ Exported 5 edges of type 'RELATES_TO' to db/falkordb_data/edges_RELATES_TO.csv\n",
      "‚úÖ Exported 3 edges of type 'MENTIONS' to db/falkordb_data/edges_MENTIONS.csv\n",
      "\n",
      "üìä Summary:\n",
      "   Node labels exported: 3\n",
      "   Edge types exported: 2\n"
     ]
    }
   ],
   "source": [
    "from src.graphiti_utils import export_graph\n",
    "\n",
    "export_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e943c21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await graphiti.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50f60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'431b8d87-97be-4190-b4a6-b00beb876996'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'group_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'pokemon_data_tmp'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8873100c-caf7-4449-8d1d-09917aa91954'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'a4845689-b82e-4543-9006-824fdc18c800'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">413780</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HAS_TYPE'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fact'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Charizard is a Fire type'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'episodes'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'5eec7d0c-807d-4de5-9b98-03a8606b2044'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ce791719-c1f5-4e11-810a-c4f508759064'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'expired_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'valid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">696458</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'invalid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'uuid'\u001b[0m: \u001b[32m'431b8d87-97be-4190-b4a6-b00beb876996'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'group_id'\u001b[0m: \u001b[32m'pokemon_data_tmp'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'source_node_uuid'\u001b[0m: \u001b[32m'8873100c-caf7-4449-8d1d-09917aa91954'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'target_node_uuid'\u001b[0m: \u001b[32m'a4845689-b82e-4543-9006-824fdc18c800'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'created_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m40\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m413780\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'HAS_TYPE'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'fact'\u001b[0m: \u001b[32m'Charizard is a Fire type'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'episodes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'5eec7d0c-807d-4de5-9b98-03a8606b2044'\u001b[0m, \u001b[32m'ce791719-c1f5-4e11-810a-c4f508759064'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'expired_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'valid_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m696458\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'invalid_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'17cd9b50-2d9d-4f8d-88ff-392bb10080aa'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'group_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'pokemon_data_tmp'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8873100c-caf7-4449-8d1d-09917aa91954'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'325c4c98-27c6-4c8c-bf0b-2787bef0388b'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">192619</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HAS_TYPE'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fact'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Charizard is a Flying type Pok√©mon'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'episodes'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'ce791719-c1f5-4e11-810a-c4f508759064'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'5eec7d0c-807d-4de5-9b98-03a8606b2044'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   ‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'68e56612-52b4-4515-a5c2-9f9e980e6af2'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'expired_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'valid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">696458</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'invalid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'uuid'\u001b[0m: \u001b[32m'17cd9b50-2d9d-4f8d-88ff-392bb10080aa'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'group_id'\u001b[0m: \u001b[32m'pokemon_data_tmp'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'source_node_uuid'\u001b[0m: \u001b[32m'8873100c-caf7-4449-8d1d-09917aa91954'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'target_node_uuid'\u001b[0m: \u001b[32m'325c4c98-27c6-4c8c-bf0b-2787bef0388b'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'created_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m40\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m192619\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'HAS_TYPE'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'fact'\u001b[0m: \u001b[32m'Charizard is a Flying type Pok√©mon'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'episodes'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "\u001b[2;32m‚îÇ   ‚îÇ   \u001b[0m\u001b[32m'ce791719-c1f5-4e11-810a-c4f508759064'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   ‚îÇ   \u001b[0m\u001b[32m'5eec7d0c-807d-4de5-9b98-03a8606b2044'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   ‚îÇ   \u001b[0m\u001b[32m'68e56612-52b4-4515-a5c2-9f9e980e6af2'\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'expired_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'valid_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m696458\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'invalid_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from graphiti_core.edges import EntityEdge\n",
    "\n",
    "results = await graphiti.search('Charizard')\n",
    "\n",
    "def pretty_print(entity_edge: EntityEdge):\n",
    "    e_dict = entity_edge.model_dump().items()\n",
    "    return {\"source\": e_dict}\n",
    "\n",
    "for result in results[:2]:\n",
    "    pretty_print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58018b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for: 'Pikachu evolution item'\n",
      "\n",
      "Search Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'group_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\\\_'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'79de5f46-96a9-4707-8414-2f48d2dc2cc6'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">934315</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'RELATES_TO'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fact'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Pikachu has type electric'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'episodes'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'5879af07-b064-4073-9ab1-3fbd65219e6e'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'expired_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'valid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384582</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'invalid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'uuid'\u001b[0m: \u001b[32m'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'group_id'\u001b[0m: \u001b[32m'\\\\_'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'source_node_uuid'\u001b[0m: \u001b[32m'79de5f46-96a9-4707-8414-2f48d2dc2cc6'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'target_node_uuid'\u001b[0m: \u001b[32m'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'created_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m934315\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'RELATES_TO'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'fact'\u001b[0m: \u001b[32m'Pikachu has type electric'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'episodes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'5879af07-b064-4073-9ab1-3fbd65219e6e'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'expired_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'valid_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m21\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m384582\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'invalid_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for: 'type disadvantage against Ground'\n",
      "\n",
      "Search Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'group_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'\\\\_'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'source_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'79de5f46-96a9-4707-8414-2f48d2dc2cc6'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'target_node_uuid'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">934315</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'RELATES_TO'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'fact'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Pikachu has type electric'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'episodes'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'5879af07-b064-4073-9ab1-3fbd65219e6e'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'expired_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'valid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">datetime.datetime</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384582</span>, <span style=\"color: #808000; text-decoration-color: #808000\">tzinfo</span>=<span style=\"color: #800080; text-decoration-color: #800080\">datetime</span>.timezone.utc<span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'invalid_at'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'attributes'</span>: <span style=\"font-weight: bold\">{}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'uuid'\u001b[0m: \u001b[32m'7ce6b315-e3a4-4752-82cd-c3ab9a671d81'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'group_id'\u001b[0m: \u001b[32m'\\\\_'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'source_node_uuid'\u001b[0m: \u001b[32m'79de5f46-96a9-4707-8414-2f48d2dc2cc6'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'target_node_uuid'\u001b[0m: \u001b[32m'7bd256cb-026c-45bc-b31b-e1c719dc4c9b'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'created_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m15\u001b[0m, \u001b[1;36m32\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m934315\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'RELATES_TO'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'fact'\u001b[0m: \u001b[32m'Pikachu has type electric'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'episodes'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'5879af07-b064-4073-9ab1-3fbd65219e6e'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'expired_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'valid_at'\u001b[0m: \u001b[1;35mdatetime.datetime\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m2025\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m21\u001b[0m, \u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m384582\u001b[0m, \u001b[33mtzinfo\u001b[0m=\u001b[35mdatetime\u001b[0m.timezone.utc\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'invalid_at'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'attributes'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.graphiti_utils import pretty_print\n",
    "\n",
    "print(\"\\nSearching for: 'Pikachu evolution item'\")\n",
    "results = await graphiti.search('Pikachu evolution item')\n",
    "\n",
    "print('\\nSearch Results:')\n",
    "for result in results[:2]:\n",
    "    pretty_print(result)\n",
    "\n",
    "print(\"\\nSearching for: 'type disadvantage against Ground'\")\n",
    "results = await graphiti.search('type disadvantage against Ground')\n",
    "\n",
    "print('\\nSearch Results:')\n",
    "for result in results[:2]:\n",
    "    pretty_print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema: Entities & Relationships\n",
    "\n",
    "We‚Äôll constrain the LLM to produce **triples** under a small ontology.  \n",
    "This reduces hallucinations and keeps the graph clean.\n",
    "\n",
    "**Entities**\n",
    "- `Pokemon(name)`\n",
    "- `Type(name)`\n",
    "- `Move(name)`\n",
    "- `Item(name)`\n",
    "\n",
    "**Relationships (directed)**\n",
    "- `HAS_TYPE(Pokemon ‚Üí Type)`\n",
    "- `EVOLVES_TO(Pokemon ‚Üí Pokemon)`\n",
    "- `NEEDS_ITEM(Pokemon ‚Üí Item)` *(for evolutions that need an item)*\n",
    "- `LEARNS_MOVE(Pokemon ‚Üí Move)`\n",
    "- `WEAK_AGAINST(Pokemon ‚Üí Type)`\n",
    "- `RESISTS(Pokemon ‚Üí Type)`\n",
    "\n",
    "We‚Äôll create **Pydantic models** for the structured output the builder agent must return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "ValidPredicates = Literal[\n",
    "    \"HAS_TYPE\", \"EVOLVES_TO\", \"NEEDS_ITEM\", \"LEARNS_MOVE\", \"WEAK_AGAINST\", \"RESISTS\"\n",
    "]\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    subject: str = Field(description=\"Entity name (e.g., 'Pikachu')\")\n",
    "    predicate: ValidPredicates\n",
    "    object: str = Field(description=\"Entity name (e.g., 'Electric')\")\n",
    "    fact: Optional[str] = Field(default=None, description=\"Optional natural language gloss for the edge\")\n",
    "    # optional metadata\n",
    "    confidence: float = Field(ge=0.0, le=1.0, default=0.9)\n",
    "\n",
    "class BuildKGResult(BaseModel):\n",
    "    entities: List[str] = Field(description=\"All entity names referenced in triples\")\n",
    "    triples: List[Triple]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. KG Builder Agent (with self‚Äëreflection)\n",
    "\n",
    "We create two agents:\n",
    "1. **Builder** ‚Äî extracts **schema‚Äëvalid triples** for a user query, constrained to our tiny dataset.\n",
    "2. **Critic** ‚Äî validates the builder‚Äôs output for **schema, consistency, and data grounding**; suggests a corrected set if needed.\n",
    "\n",
    "We‚Äôll run a simple **reflect‚Äërevise loop** up to 2 rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "model = OpenAIModel(model=MODEL)\n",
    "\n",
    "builder = Agent[None, BuildKGResult](\n",
    "    model=model,\n",
    "    system_prompt=(\n",
    "        \"You are a strict KG builder. Extract schema-conformant triples ONLY from the provided Pikachu dataset. \"\n",
    "        \"Never invent new pokemon, types, or moves. The schema is:\\n\"\n",
    "        \"- Entities: Pokemon, Type, Move, Item (use names as strings)\\n\"\n",
    "        \"- Rels: HAS_TYPE(Pokemon‚ÜíType), EVOLVES_TO(Pokemon‚ÜíPokemon), NEEDS_ITEM(Pokemon‚ÜíItem), \"\n",
    "        \"LEARNS_MOVE(Pokemon‚ÜíMove), WEAK_AGAINST(Pokemon‚ÜíType), RESISTS(Pokemon‚ÜíType)\\n\"\n",
    "        \"Return entities + triples as structured JSON. Keep subjects/objects as plain names.\"\n",
    "    ),\n",
    "    result_type=BuildKGResult,\n",
    ")\n",
    "\n",
    "class Critique(BaseModel):\n",
    "    ok: bool\n",
    "    reasons: List[str] = []\n",
    "    corrected: Optional[BuildKGResult] = None\n",
    "\n",
    "critic = Agent[BuildKGResult, Critique](\n",
    "    model=model,\n",
    "    system_prompt=(\n",
    "        \"You are a KG critic. Given a candidate BuildKGResult and the Pikachu dataset, verify:\\n\"\n",
    "        \"1) predicates are from the allowed set, 2) all entities appear in dataset, 3) no contradictions, \"\n",
    "        \"4) triples grounded in data. If any problem, set ok=false and return a corrected BuildKGResult.\"\n",
    "    ),\n",
    "    deps_type=BuildKGResult,  # the input to the agent\n",
    "    result_type=Critique,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_entities() -> set:\n",
    "    names = set()\n",
    "    for p in PIKACHU_DATA[\"pokemon\"]:\n",
    "        names.add(p[\"name\"])\n",
    "        for t in p[\"types\"]:\n",
    "            names.add(t)\n",
    "        for a in p[\"abilities\"]:\n",
    "            names.add(a)  # we won't use Ability as an entity, but keep for checks\n",
    "        for w in p[\"weak_against\"]:\n",
    "            names.add(w)\n",
    "        for r in p[\"resists\"]:\n",
    "            names.add(r)\n",
    "        if p[\"evolves_to\"]:\n",
    "            names.add(p[\"evolves_to\"])\n",
    "        if p[\"evolution_item\"]:\n",
    "            names.add(p[\"evolution_item\"])\n",
    "    for m in PIKACHU_DATA[\"moves\"]:\n",
    "        names.add(m[\"name\"]); names.add(m[\"type\"])\n",
    "    return names\n",
    "\n",
    "ALL_KNOWN = dataset_entities()\n",
    "\n",
    "def seed_moves_for(pokemon_name: str) -> List[str]:\n",
    "    # For demo, give a couple of canonical moves\n",
    "    base = {\n",
    "        \"Pichu\": [\"Thunder Wave\", \"Quick Attack\"],\n",
    "        \"Pikachu\": [\"Thunderbolt\", \"Quick Attack\"],\n",
    "        \"Raichu\": [\"Thunderbolt\"]\n",
    "    }\n",
    "    return base.get(pokemon_name, [])\n",
    "\n",
    "def build_kg_for_query(query: str, max_reflections: int = 2) -> BuildKGResult:\n",
    "    # 1) Initial draft\n",
    "    draft = builder.run_sync(f\"Query: {query}\\nDataset (JSON): {json.dumps(PIKACHU_DATA)}\").output\n",
    "\n",
    "    # 2) Critique loop\n",
    "    current = draft\n",
    "    for i in range(max_reflections):\n",
    "        critique = critic.run_sync(\n",
    "            deps=current,\n",
    "            user_message=f\"Check this candidate against dataset. Return ok and corrected if needed.\"\n",
    "        ).output\n",
    "        if critique.ok:\n",
    "            return current\n",
    "        if critique.corrected is not None:\n",
    "            current = critique.corrected\n",
    "    return current\n",
    "\n",
    "# quick smoke test\n",
    "res = build_kg_for_query(\"How does Pikachu evolve and what item is needed? Also list its type and a typical move.\")\n",
    "print(\"Triples:\", len(res.triples))\n",
    "print(res.triples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Persisting to Graphiti\n",
    "\n",
    "We‚Äôll keep a single graph instance for the demo and add triples to it.  \n",
    "If Graphiti is not installed here, we‚Äôll use a small in‚Äëmemory shim with a compatible `add_triplet()` / `neighborhood()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH = Graph()\n",
    "\n",
    "def add_build_result_to_graph(result: BuildKGResult):\n",
    "    for tri in result.triples:\n",
    "        GRAPH.add_triplet(tri.subject, tri.predicate, tri.object, fact=tri.fact or \"\", confidence=tri.confidence)\n",
    "\n",
    "result = build_kg_for_query(\"Create a small KG for Pikachu: type, evolution chain, weaknesses, and one move.\")\n",
    "add_build_result_to_graph(result)\n",
    "print(\"Graph nodes:\", getattr(GRAPH, \"nodes\", \"N/A (backend-managed)\"))\n",
    "try:\n",
    "    print(\"Edges stored:\", len(GRAPH.edges))\n",
    "except Exception:\n",
    "    print(\"Edges stored: backend-managed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KG Answering Agent (with **KG builder tool**)\n",
    "\n",
    "The answering agent can:\n",
    "1. **Query the existing KG** for facts, and\n",
    "2. **If missing**, call the **`build_kg_for_query` tool** to generate & persist the relevant subgraph, then answer.\n",
    "\n",
    "This keeps answers **precise and grounded**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "    used_builder: bool = False\n",
    "    evidence: List[Tuple[str, str, str]] = Field(default_factory=list, description=\"subset of triples (s,p,o) used\")\n",
    "\n",
    "answer_agent = Agent[None, Answer](\n",
    "    model=model,\n",
    "    system_prompt=(\n",
    "        \"You answer questions strictly from the Knowledge Graph.\\n\"\n",
    "        \"If the graph does not have sufficient edges to answer, call `make_or_update_graph` tool first, then answer.\\n\"\n",
    "        \"Cite a few (s,p,o) triples used in `evidence`. Be concise and precise.\"\n",
    "    ),\n",
    "    result_type=Answer\n",
    ")\n",
    "\n",
    "@answer_agent.tool\n",
    "def make_or_update_graph(ctx: RunContext[None], query: str) -> str:\n",
    "    \\\"\\\"\\\"Generate/augment the knowledge graph for the user query and persist it; returns a short status string.\\\"\\\"\\\"\n",
    "    result = build_kg_for_query(query)\n",
    "    add_build_result_to_graph(result)\n",
    "    return f\\\"Added {len(result.triples)} triples for query: {query}\\\"\n",
    "\n",
    "def query_graph_edges(subject=None, predicate=None, object=None):\n",
    "    try:\n",
    "        return GRAPH.find_edges(subject=subject, predicate=predicate, object=object)\n",
    "    except Exception:\n",
    "        # If using a real backend, you'd use Graphiti's query API here\n",
    "        return []\n",
    "\n",
    "def answer_with_graph(question: str) -> Answer:\n",
    "    # Optional: pre-check simple availability to guide the LLM\n",
    "    neigh = getattr(GRAPH, \"neighborhood\", None)\n",
    "    hint = \"\"\n",
    "    if neigh is not None:\n",
    "        # naive hint: do we have any neighbors for the main mentioned entity?\n",
    "        if \"Pikachu\" in question:\n",
    "            neighborhood = GRAPH.neighborhood(\"Pikachu\")\n",
    "            if not neighborhood:\n",
    "                hint = \"(Graph appears sparse for Pikachu; consider calling the builder tool.)\"\n",
    "    return answer_agent.run_sync(f\\\"{hint}\\\\nQuestion: {question}\\\").output\n",
    "\n",
    "demo = answer_with_graph(\"What item evolves Pikachu, and what type is Pikachu?\")\n",
    "print(demo.answer, \"\\\\nUsed builder:\", demo.used_builder, \"\\\\nEvidence:\", demo.evidence[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demos\n",
    "\n",
    "Try a few queries. The agent will use the graph if possible and call the builder tool if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in [\n",
    "    \"List Pikachu's evolution chain.\",\n",
    "    \"Is Pikachu weak against Ground?\",\n",
    "    \"Give Pikachu's type and one move it commonly uses.\",\n",
    "    \"What item is needed to evolve Pikachu?\"\n",
    "]:\n",
    "    out = answer_with_graph(q)\n",
    "    print(\"Q:\", q)\n",
    "    print(\"A:\", out.answer)\n",
    "    print(\"Used builder tool:\", out.used_builder)\n",
    "    print(\"Evidence:\", out.evidence[:2])\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reliability: lightweight checks\n",
    "\n",
    "You can add more *guardrails*:\n",
    "- **Result validator** to clip/normalize fields or reject low‚Äëconfidence triples.\n",
    "- **Critic iterations** > 2 for tougher tasks.\n",
    "- **Schema hardening**: restrict entity strings to known lists, require certain edges per query type, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: clip confidence to [0.0, 1.0] and drop very low-confidence edges before persisting\n",
    "def sanitize(result: BuildKGResult, min_conf: float = 0.4) -> BuildKGResult:\n",
    "    keep = []\n",
    "    for tri in result.triples:\n",
    "        tri.confidence = max(0.0, min(1.0, tri.confidence))\n",
    "        if tri.confidence >= min_conf:\n",
    "            keep.append(tri)\n",
    "    return BuildKGResult(entities=sorted(set(result.entities)), triples=keep)\n",
    "\n",
    "# Use it like:\n",
    "r = build_kg_for_query(\"Ensure one move and type for Pikachu\")\n",
    "r = sanitize(r, min_conf=0.5)\n",
    "add_build_result_to_graph(r)\n",
    "print(\"Sanitized & persisted\", len(r.triples), \"triples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Backend choices & performance notes\n",
    "\n",
    "- Graphiti supports **Neo4j, FalkorDB, K√πzu, Amazon Neptune** backends and uses **OpenSearch** for full‚Äëtext where relevant.  \n",
    "  See Graphiti README **Requirements** and quickstart.  \n",
    "- Try **FalkorDB** with Docker for a zero‚Äësetup local graph; or use **Neo4j Desktop**.\n",
    "\n",
    "> If using FalkorDB/Neo4j, replace the shim here with real Graphiti usage and its query utilities; method names like `add_triplet` and neighborhood/edge lookup map onto Graphiti‚Äôs graph API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. References & further reading\n",
    "\n",
    "- Graphiti overview & install (README) ‚Äî *requirements, structured output note, backends, MCP server*:  \n",
    "  - https://github.com/getzep/graphiti  \n",
    "  - https://help.getzep.com/graphiti/getting-started/overview  \n",
    "  - MCP server intro: https://help.getzep.com/graphiti/getting-started/mcp-server\n",
    "\n",
    "- PydanticAI ‚Äî *tools & structured outputs*:  \n",
    "  - Tools: https://ai.pydantic.dev/tools/  \n",
    "  - Output / structured results: https://ai.pydantic.dev/output/\n",
    "\n",
    "- Why KG for agents (temporal, dynamic):  \n",
    "  - Neo4j blog summary of Graphiti: https://neo4j.com/blog/developer/graphiti-knowledge-graph-memory/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. What you learned üí°\n",
    "\n",
    "- Designing a **schema-first** KG eliminates a lot of mess.\n",
    "- A **builder‚Üícritic** loop catches schema violations & hallucinations early.\n",
    "- An **answering agent with a KG-builder tool** gives **on‚Äëdemand graphing** + **precise answers**.\n",
    "- This pattern scales to larger domains and document corpora (‚Üí **GraphRAG**). In the next tutorial, we‚Äôll compare **dynamic Graphiti** with **precomputed GraphRAG** and hybridize them."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tutorial 5 ‚Äî Dynamic KGs with Graphiti + PydanticAI (Pikachu)"
  },
  "kernelspec": {
   "display_name": "build-your-own-super-agents (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
